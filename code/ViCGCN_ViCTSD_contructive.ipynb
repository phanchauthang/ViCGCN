{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qm_DII13AYh"
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIQOehLKtNXL",
        "outputId": "6ca69d21-c390-4463-fd82-5860ae3a19f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl-cu102\n",
            "  Downloading dgl_cu102-0.6.1-cp38-cp38-manylinux1_x86_64.whl (36.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.8 MB 135 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102) (2.8.8)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102) (1.7.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102) (3.0.4)\n",
            "Installing collected packages: dgl-cu102\n",
            "Successfully installed dgl-cu102-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre dgl-cu102\n",
        "!pip install --upgrade gdown\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehe40OJKSLNk",
        "outputId": "dcf9e666-23c7-4687-e9ed-31507d4fbf5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Wed_Oct_23_19:24:38_PDT_2019\n",
            "Cuda compilation tools, release 10.2, V10.2.89\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE7QcgfWtkqa"
      },
      "source": [
        "# source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQtcxg8Tz4-u"
      },
      "source": [
        "### import packet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc1BTagiz7aF",
        "outputId": "400cc79a-a2b8-444d-a6e9-1593b97e4a47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import scipy.sparse as sp\n",
        "import sys\n",
        "import dgl\n",
        "from torch.nn import Module, Dropout\n",
        "from dgl.nn.pytorch import GraphConv\n",
        "from torch.nn.functional import relu, softmax\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.nn import Module, Linear\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import scipy.sparse as sp\n",
        "from math import log\n",
        "from sklearn import svm\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "from torch.utils.data import DataLoader\n",
        "from random import shuffle\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import collections\n",
        "import math\n",
        "from scipy.sparse import coo_matrix\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import nll_loss,cross_entropy\n",
        "import torch\n",
        "from numpy import mean\n",
        "from torch import log\n",
        "from torch.nn.functional import softmax\n",
        "from torch.optim import lr_scheduler,AdamW\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80OLAh0reCJ-"
      },
      "source": [
        "### set data_set name "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8MM13xu2eEzW"
      },
      "outputs": [],
      "source": [
        "# Vion VSMEC   ViCTSD \n",
        "dataet_name = 'ViCTSD'\n",
        "f1_type = 'binary'\n",
        "if dataet_name == 'VSMEC' or dataet_name == 'ViCTSD':\n",
        "  f1_type = 'macro'\n",
        "elif dataet_name == 'Vion' :\n",
        "  f1_type = 'weighted'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpewssfyyRi"
      },
      "source": [
        "### util "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PsscSuMeywQL"
      },
      "outputs": [],
      "source": [
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "\n",
        "\n",
        "def get_file(choice):\n",
        "    file_dict = {\"R8\": 'R8.txt', 'ohsumed': 'ohsumed.txt', '20news': \"20ng.txt\", 'mr': 'mr.txt','SVMC': 'SVMC.txt'}\n",
        "    if choice not in file_dict.keys():\n",
        "        raise FileNotFoundError\n",
        "    return file_dict[choice]\n",
        "\n",
        "\n",
        "def clean_str(string):\n",
        "    # string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    # string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    # string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    # string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    # string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    # string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    # string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    # string = re.sub(r\",\", \" , \", string)\n",
        "    # string = re.sub(r\"!\", \" ! \", string)\n",
        "    # string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    # string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    # string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    # string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip().lower()\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "def parse_index_file(filename):\n",
        "    \"\"\"Parse index file.\"\"\"\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "\n",
        "\n",
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "\n",
        "def load_corpus(dataset_str):\n",
        "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'adj']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"/content/data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "\n",
        "    x, y, tx, ty, allx, ally, adj = tuple(objects)\n",
        "    print(x.shape, y.shape, tx.shape, ty.shape, allx.shape, ally.shape)\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    labels = np.vstack((ally, ty))\n",
        "    print(len(labels))\n",
        "\n",
        "    train_idx_orig = parse_index_file(\n",
        "        \"/content/data/{}.train.index\".format(dataset_str))\n",
        "    train_size = len(train_idx_orig)\n",
        "\n",
        "    val_size = train_size - x.shape[0]\n",
        "    test_size = tx.shape[0]\n",
        "\n",
        "    idx_train = range(len(y))\n",
        "    idx_val = range(len(y), len(y) + val_size)\n",
        "    idx_test = range(allx.shape[0], allx.shape[0] + test_size)\n",
        "\n",
        "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
        "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
        "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
        "\n",
        "    y_train = np.zeros(labels.shape)\n",
        "    y_val = np.zeros(labels.shape)\n",
        "    y_test = np.zeros(labels.shape)\n",
        "    y_train[train_mask, :] = labels[train_mask, :]\n",
        "    y_val[val_mask, :] = labels[val_mask, :]\n",
        "    y_test[test_mask, :] = labels[test_mask, :]\n",
        "\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size\n",
        "setup_seed(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjon6T-OtmPb"
      },
      "source": [
        "## model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OP_WL-h7tlUz"
      },
      "outputs": [],
      "source": [
        "class finetunedphoBert(Module):\n",
        "    def __init__(self, class_num):\n",
        "        super().__init__()\n",
        "        #bert-base-uncased\n",
        "        # self.model = RobertaModel.from_pretrained('/content/PhoBERT_base_fairseq', checkpoint_file='model.pt', bpe='fastbpe', bpe_codes='/content/PhoBERT_base_fairseq/bpe.codes').eval()\n",
        "        self.model = AutoModel.from_pretrained('vinai/phobert-base')\n",
        "        # self.model = AutoModel.from_pretrained('bert-base-uncased')\n",
        "        self.linear = Linear(768, class_num)\n",
        "\n",
        "    def forward(self, input):\n",
        "        predict = self.model(input).last_hidden_state[:,0,:]\n",
        "        return self.linear(predict)\n",
        "\n",
        "class GCN(Module):\n",
        "    def __init__(self, class_num):\n",
        "        super().__init__()\n",
        "        self.Conv1 = GraphConv(768, 200, weight=True, activation=relu)\n",
        "        self.Conv2 = GraphConv(200, class_num, weight=True)\n",
        "        self.dropout=Dropout(0.1)\n",
        "        self.dropout2=Dropout(0.2)\n",
        "\n",
        "\n",
        "    def forward(self, graph: dgl.graph, feature: torch.tensor):\n",
        "        predict1 = self.dropout(self.Conv1(graph, feature, edge_weight=graph.edata['w']))\n",
        "        predict2 = self.dropout2(self.Conv2(graph, predict1, edge_weight=graph.edata['w']))\n",
        "        return predict2\n",
        "\n",
        "\n",
        "class phoBertGCN(Module):\n",
        "    def __init__(self, pretrained_path, label_size, lam=0.3):\n",
        "        \"\"\"\n",
        "        :param pretrained_path: path to pretrained bert model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.phoBertModel = finetunedphoBert(label_size)\n",
        "        self.phoBertModel.load_state_dict(torch.load(pretrained_path))\n",
        "        self.gcn = GCN(label_size)\n",
        "        self.lam = lam\n",
        "\n",
        "    def forward(self, sentences, features,attention, graph, indexs):\n",
        "        last_predict = self.phoBertModel.model(sentences,attention_mask=attention).last_hidden_state[:, 0, :]\n",
        "        features[indexs] = last_predict.detach()\n",
        "        gcn_predict = self.gcn(graph, features)\n",
        "        bert_predict = self.phoBertModel.linear(last_predict)\n",
        "        predict = softmax(gcn_predict[indexs], -1) * self.lam + (1 - self.lam) * softmax(bert_predict, -1)\n",
        "        return predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47A_nGouvJVi"
      },
      "source": [
        "## buildgraph for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRmMoPSdvKs8",
        "outputId": "f1136363-3df9-477d-fdc0-402bc813adac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7000, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7051, 7052, 7053, 7054, 7055, 7056, 7057, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7068, 7069, 7070, 7071, 7072, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7085, 7086, 7087, 7088, 7089, 7090, 7091, 7092, 7093, 7094, 7095, 7096, 7097, 7098, 7099, 7100, 7101, 7102, 7103, 7104, 7105, 7106, 7107, 7108, 7109, 7110, 7111, 7112, 7113, 7114, 7115, 7116, 7117, 7118, 7119, 7120, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7128, 7129, 7130, 7131, 7132, 7133, 7134, 7135, 7136, 7137, 7138, 7139, 7140, 7141, 7142, 7143, 7144, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7152, 7153, 7154, 7155, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7203, 7204, 7205, 7206, 7207, 7208, 7209, 7210, 7211, 7212, 7213, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7246, 7247, 7248, 7249, 7250, 7251, 7252, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298, 7299, 7300, 7301, 7302, 7303, 7304, 7305, 7306, 7307, 7308, 7309, 7310, 7311, 7312, 7313, 7314, 7315, 7316, 7317, 7318, 7319, 7320, 7321, 7322, 7323, 7324, 7325, 7326, 7327, 7328, 7329, 7330, 7331, 7332, 7333, 7334, 7335, 7336, 7337, 7338, 7339, 7340, 7341, 7342, 7343, 7344, 7345, 7346, 7347, 7348, 7349, 7350, 7351, 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7359, 7360, 7361, 7362, 7363, 7364, 7365, 7366, 7367, 7368, 7369, 7370, 7371, 7372, 7373, 7374, 7375, 7376, 7377, 7378, 7379, 7380, 7381, 7382, 7383, 7384, 7385, 7386, 7387, 7388, 7389, 7390, 7391, 7392, 7393, 7394, 7395, 7396, 7397, 7398, 7399, 7400, 7401, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7409, 7410, 7411, 7412, 7413, 7414, 7415, 7416, 7417, 7418, 7419, 7420, 7421, 7422, 7423, 7424, 7425, 7426, 7427, 7428, 7429, 7430, 7431, 7432, 7433, 7434, 7435, 7436, 7437, 7438, 7439, 7440, 7441, 7442, 7443, 7444, 7445, 7446, 7447, 7448, 7449, 7450, 7451, 7452, 7453, 7454, 7455, 7456, 7457, 7458, 7459, 7460, 7461, 7462, 7463, 7464, 7465, 7466, 7467, 7468, 7469, 7470, 7471, 7472, 7473, 7474, 7475, 7476, 7477, 7478, 7479, 7480, 7481, 7482, 7483, 7484, 7485, 7486, 7487, 7488, 7489, 7490, 7491, 7492, 7493, 7494, 7495, 7496, 7497, 7498, 7499, 7500, 7501, 7502, 7503, 7504, 7505, 7506, 7507, 7508, 7509, 7510, 7511, 7512, 7513, 7514, 7515, 7516, 7517, 7518, 7519, 7520, 7521, 7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554, 7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565, 7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576, 7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587, 7588, 7589, 7590, 7591, 7592, 7593, 7594, 7595, 7596, 7597, 7598, 7599, 7600, 7601, 7602, 7603, 7604, 7605, 7606, 7607, 7608, 7609, 7610, 7611, 7612, 7613, 7614, 7615, 7616, 7617, 7618, 7619, 7620, 7621, 7622, 7623, 7624, 7625, 7626, 7627, 7628, 7629, 7630, 7631, 7632, 7633, 7634, 7635, 7636, 7637, 7638, 7639, 7640, 7641, 7642, 7643, 7644, 7645, 7646, 7647, 7648, 7649, 7650, 7651, 7652, 7653, 7654, 7655, 7656, 7657, 7658, 7659, 7660, 7661, 7662, 7663, 7664, 7665, 7666, 7667, 7668, 7669, 7670, 7671, 7672, 7673, 7674, 7675, 7676, 7677, 7678, 7679, 7680, 7681, 7682, 7683, 7684, 7685, 7686, 7687, 7688, 7689, 7690, 7691, 7692, 7693, 7694, 7695, 7696, 7697, 7698, 7699, 7700, 7701, 7702, 7703, 7704, 7705, 7706, 7707, 7708, 7709, 7710, 7711, 7712, 7713, 7714, 7715, 7716, 7717, 7718, 7719, 7720, 7721, 7722, 7723, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7732, 7733, 7734, 7735, 7736, 7737, 7738, 7739, 7740, 7741, 7742, 7743, 7744, 7745, 7746, 7747, 7748, 7749, 7750, 7751, 7752, 7753, 7754, 7755, 7756, 7757, 7758, 7759, 7760, 7761, 7762, 7763, 7764, 7765, 7766, 7767, 7768, 7769, 7770, 7771, 7772, 7773, 7774, 7775, 7776, 7777, 7778, 7779, 7780, 7781, 7782, 7783, 7784, 7785, 7786, 7787, 7788, 7789, 7790, 7791, 7792, 7793, 7794, 7795, 7796, 7797, 7798, 7799, 7800, 7801, 7802, 7803, 7804, 7805, 7806, 7807, 7808, 7809, 7810, 7811, 7812, 7813, 7814, 7815, 7816, 7817, 7818, 7819, 7820, 7821, 7822, 7823, 7824, 7825, 7826, 7827, 7828, 7829, 7830, 7831, 7832, 7833, 7834, 7835, 7836, 7837, 7838, 7839, 7840, 7841, 7842, 7843, 7844, 7845, 7846, 7847, 7848, 7849, 7850, 7851, 7852, 7853, 7854, 7855, 7856, 7857, 7858, 7859, 7860, 7861, 7862, 7863, 7864, 7865, 7866, 7867, 7868, 7869, 7870, 7871, 7872, 7873, 7874, 7875, 7876, 7877, 7878, 7879, 7880, 7881, 7882, 7883, 7884, 7885, 7886, 7887, 7888, 7889, 7890, 7891, 7892, 7893, 7894, 7895, 7896, 7897, 7898, 7899, 7900, 7901, 7902, 7903, 7904, 7905, 7906, 7907, 7908, 7909, 7910, 7911, 7912, 7913, 7914, 7915, 7916, 7917, 7918, 7919, 7920, 7921, 7922, 7923, 7924, 7925, 7926, 7927, 7928, 7929, 7930, 7931, 7932, 7933, 7934, 7935, 7936, 7937, 7938, 7939, 7940, 7941, 7942, 7943, 7944, 7945, 7946, 7947, 7948, 7949, 7950, 7951, 7952, 7953, 7954, 7955, 7956, 7957, 7958, 7959, 7960, 7961, 7962, 7963, 7964, 7965, 7966, 7967, 7968, 7969, 7970, 7971, 7972, 7973, 7974, 7975, 7976, 7977, 7978, 7979, 7980, 7981, 7982, 7983, 7984, 7985, 7986, 7987, 7988, 7989, 7990, 7991, 7992, 7993, 7994, 7995, 7996, 7997, 7998, 7999]\n",
            "[3280, 5953, 5004, 4985, 6520, 2999, 4267, 2735, 4270, 117, 5754, 5679, 5207, 5035, 6744, 4166, 3431, 541, 3276, 6557, 1636, 2684, 4872, 6855, 3915, 3105, 2049, 3205, 6556, 6607, 2090, 1495, 3268, 5627, 1790, 3373, 1594, 5804, 6537, 115, 3178, 271, 2831, 7, 5693, 1858, 6633, 4786, 4039, 4808, 6741, 5290, 3953, 5540, 5545, 3013, 4312, 4089, 2046, 1613, 745, 6170, 3101, 2258, 2266, 3301, 1871, 5255, 1528, 1947, 6062, 4602, 6097, 711, 4651, 2214, 5238, 1130, 2373, 6061, 6452, 2545, 4130, 6431, 83, 1759, 3643, 4434, 6038, 1407, 1182, 2170, 4952, 6075, 3325, 4631, 4900, 5353, 4252, 5069, 6859, 3469, 2215, 2231, 6817, 406, 1510, 2616, 5010, 592, 2379, 3687, 6105, 5427, 642, 4114, 3629, 6590, 2594, 644, 978, 6997, 3122, 4990, 4364, 1788, 5702, 1220, 2527, 6454, 6492, 4670, 6361, 4674, 5406, 5076, 336, 1362, 3474, 1651, 6629, 1618, 686, 4825, 6985, 4584, 1438, 3711, 5442, 5392, 2201, 237, 586, 6539, 2390, 4326, 319, 309, 3458, 1151, 3870, 5527, 5620, 2271, 6064, 1410, 6896, 2319, 1446, 1055, 6901, 2077, 5175, 6405, 255, 2556, 1620, 3017, 6691, 3371, 6684, 1580, 3647, 4828, 79, 5446, 843, 1900, 3131, 2585, 1904, 1212, 4458, 947, 3363, 4803, 3153, 2411, 104, 4484, 1024, 4158, 2716, 3351, 6784, 3057, 1284, 1801, 5760, 2710, 39, 4671, 3349, 4479, 5686, 3614, 6100, 2801, 5185, 2061, 5526, 6369, 2830, 5485, 5400, 6679, 3532, 4837, 4827, 5588, 228, 227, 696, 5299, 5078, 3862, 3256, 4975, 3980, 3682, 2242, 4037, 32, 4624, 4506, 1859, 4515, 6627, 3819, 490, 4320, 6380, 6291, 1222, 5564, 3546, 608, 1564, 5476, 1503, 108, 824, 6107, 5984, 6747, 6459, 356, 874, 6434, 3765, 1076, 5689, 1747, 1512, 3817, 3769, 5587, 5516, 5241, 3370, 1056, 1838, 6083, 2738, 1213, 5435, 6875, 5106, 6670, 1064, 1640, 2139, 246, 6974, 5292, 2026, 898, 3202, 5007, 2610, 6617, 2729, 1038, 5750, 5920, 4395, 2513, 3795, 2990, 3582, 522, 5914, 5988, 3525, 139, 3208, 3512, 903, 382, 2420, 2928, 62, 2966, 6343, 3100, 3226, 5907, 2035, 2099, 5415, 1025, 4414, 4098, 899, 2899, 262, 4983, 1592, 3552, 3868, 3278, 3007, 648, 2509, 2853, 2175, 861, 6196, 3813, 4966, 6429, 866, 4635, 2129, 4380, 6650, 3173, 4179, 3594, 6477, 3920, 5066, 1630, 2640, 286, 2487, 4609, 3354, 3991, 17, 5572, 2428, 3377, 578, 6354, 2073, 6435, 3731, 3244, 6249, 2431, 5349, 429, 6401, 4010, 3709, 6362, 3686, 6309, 6905, 73, 5902, 6045, 6208, 734, 5844, 6887, 3950, 3828, 525, 2669, 2768, 3330, 146, 3091, 6120, 3968, 5011, 3527, 2166, 3721, 252, 6092, 3620, 1299, 3410, 6072, 634, 1777, 233, 904, 1590, 1960, 1370, 2083, 2673, 5375, 3575, 3971, 1228, 6612, 5978, 5248, 5456, 1648, 1206, 5267, 2552, 2730, 1339, 3912, 6467, 3538, 2147, 1504, 2547, 1962, 3462, 5968, 5740, 2714, 4031, 822, 3476, 1259, 1670, 4931, 6311, 2574, 6889, 2859, 1144, 5801, 327, 6731, 4237, 3867, 6581, 5264, 4053, 1668, 470, 2749, 4553, 4762, 5371, 4637, 2338, 6742, 2622, 6597, 936, 3943, 2017, 6504, 4559, 2163, 6030, 4881, 4199, 4418, 6111, 6871, 2309, 5497, 165, 819, 1672, 2561, 3636, 351, 3359, 6770, 1285, 6268, 2013, 4097, 4334, 2190, 1710, 6944, 990, 5041, 4344, 4415, 3845, 4299, 1738, 2375, 5681, 1931, 782, 3019, 5300, 385, 3561, 1975, 258, 5752, 5328, 1682, 4478, 2386, 1293, 2330, 3726, 57, 6433, 4555, 5982, 6609, 6898, 6272, 6179, 1712, 6739, 3505, 4347, 683, 486, 3468, 651, 6586, 4256, 2489, 1909, 162, 1533, 6267, 3000, 2075, 897, 4920, 573, 6040, 4229, 1918, 129, 6988, 1902, 4260, 1547, 2053, 3099, 609, 5673, 2595, 5975, 5081, 5974, 412, 6508, 2922, 1951, 5310, 5807, 3891, 5109, 1045, 1319, 3526, 6563, 2512, 2526, 288, 3737, 113, 6602, 3247, 5464, 447, 289, 4093, 6966, 4928, 4505, 2249, 539, 2453, 4349, 6624, 355, 2153, 1989, 1534, 2782, 3034, 5932, 575, 2559, 1650, 4534, 6046, 5785, 1755, 5117, 2877, 1089, 320, 1435, 3735, 3630, 4898, 1305, 5225, 5262, 1579, 426, 6588, 4269, 3898, 3419, 2369, 6198, 3389, 6780, 5022, 3681, 4858, 2819, 207, 120, 6917, 5240, 913, 2298, 4048, 6976, 1624, 1539, 540, 1068, 2459, 1916, 2014, 1600, 1229, 2815, 2823, 1820, 6781, 4963, 4026, 4087, 1173, 566, 787, 6206, 882, 5341, 1211, 2169, 6926, 2004, 3030, 5783, 5082, 415, 1996, 4322, 3022, 5269, 2257, 2262, 6449, 1418, 5288, 25, 2108, 6661, 4314, 3843, 3486, 4790, 3956, 1412, 2001, 457, 2, 3107, 5865, 4485, 4451, 1870, 4880, 4271, 1552, 3298, 931, 3700, 436, 3518, 6893, 1033, 3540, 4839, 6340, 2722, 5433, 3623, 4904, 6420, 3565, 1770, 5504, 74, 3257, 2095, 6063, 3320, 2337, 3214, 5330, 842, 1351, 4639, 5152, 6583, 3788, 1690, 3713, 744, 497, 5065, 4014, 1335, 3910, 6190, 5849, 2184, 5157, 1423, 2702, 3092, 1116, 652, 5723, 6346, 3558, 4108, 6012, 4372, 5746, 292, 4799, 6337, 5858, 6057, 623, 409, 5193, 4207, 6644, 1079, 2189, 3750, 371, 6940, 1772, 1696, 893, 1758, 4558, 333, 5500, 2854, 2811, 3564, 6560, 2942, 4284, 6668, 1586, 6252, 6439, 3507, 6082, 1048, 1036, 6015, 4491, 6689, 5556, 2114, 1377, 3201, 3743, 2704, 2981, 3313, 190, 1270, 1997, 860, 1822, 6866, 5208, 1507, 5714, 1936, 1350, 6888, 5786, 2676, 5398, 3384, 366, 2656, 790, 3423, 840, 1323, 3219, 6659, 1753, 6300, 1582, 6789, 1296, 673, 991, 6524, 2862, 107, 6843, 5471, 2726, 3321, 3926, 5738, 4716, 3003, 6003, 2452, 1474, 5439, 3169, 5302, 5542, 4151, 4933, 1718, 877, 4112, 6638, 4564, 2745, 4746, 6237, 921, 3175, 4775, 2954, 5947, 3875, 3596, 3498, 4466, 6121, 1802, 675, 5853, 6994, 5080, 4350, 3198, 2236, 924, 38, 4921, 888, 3414, 2668, 2158, 4488, 1266, 6335, 2476, 6567, 4550, 6016, 6418, 6093, 1153, 4030, 5128, 2203, 4161, 4160, 4185, 4852, 5380, 5064, 3652, 4568, 6740, 717, 5507, 375, 6502, 2959, 3570, 3020, 3133, 6025, 5343, 340, 4697, 5622, 4743, 3470, 2115, 4848, 2429, 5640, 2742, 196, 6297, 4236, 5919, 6858, 2034, 1886, 363, 2806, 6136, 2447, 6167, 3206, 3021, 1889, 4020, 5606, 2675, 6054, 3850, 4042, 4834, 2803, 3531, 430, 1169, 4537, 6226, 206, 6298, 4282, 3403, 2442, 4209, 1020, 1905, 3369, 1793, 6262, 2403, 3098, 5513, 2051, 5332, 2109, 2741, 5691, 180, 3986, 5040, 3556, 3921, 226, 1856, 2825, 6408, 894, 2894, 6611, 4041, 376, 6236, 1136, 411, 2085, 4855, 1122, 387, 5370, 756, 3588, 6005, 4575, 3210, 6514, 1193, 4153, 1070, 2570, 818, 995, 313, 6419, 6317, 1752, 5591, 2518, 1491, 6881, 3563, 5037, 1659, 5276, 465, 6197, 3771, 6828, 4333, 6372, 1015, 5480, 3543, 4289, 3392, 2213, 2092, 5072, 2557, 257, 5814, 5548, 403, 2618, 5093, 1615, 5533, 6883, 5986, 707, 1551, 1570, 310, 5843, 5133, 6148, 795, 2416, 54, 5191, 4942, 6173, 4891, 3748, 3045, 889, 5368, 1924, 3484, 1026, 3881, 2221, 1789, 1555, 1611, 4960, 3333, 4368, 4831, 5650, 6772, 986, 1657, 4932, 5599, 3289, 1263, 2448, 1601, 6803, 2285, 4192, 4079, 1621, 2494, 3253, 6379, 796, 3672, 3305, 5893, 6285, 4905, 5946, 5519, 5034, 6951, 5428, 6801, 1117, 2415, 3215, 3346, 2608, 5973, 3842, 5379, 4133, 185, 4408, 2040, 5680, 6543, 6476, 1138, 6169, 60, 362, 6146, 5821, 6329, 2141, 3435, 1490, 4724, 829, 4576, 3128, 4148, 6701, 5422, 273, 3052, 2161, 5236, 6115, 3533, 5184, 3541, 3839, 2124, 2072, 3212, 5628, 1095, 390, 3961, 6937, 1433, 6183, 2084, 1073, 772, 511, 5327, 46, 1161, 2362, 5027, 2514, 4327, 1706, 4729, 4353, 1830, 5860, 2799, 6512, 4640, 1761, 3658, 20, 3209, 5448, 6713, 3642, 6049, 2703, 1312, 2426, 4283, 5053, 4411, 5214, 1409, 3612, 2587, 1424, 1205, 3241, 6284, 1381, 4886, 1447, 6545, 949, 2754, 461, 6404, 2666, 554, 4997, 5169, 4116, 5136, 1839, 3023, 3724, 5045, 5254, 2435, 3981, 4196, 2136, 3886, 1359, 3761, 201, 4240, 1794, 3879, 3793, 6278, 1786, 2368, 3695, 612, 3448, 2980, 342, 5142, 6526, 2604, 5220, 2932, 346, 1292, 4654, 6322, 1571, 4023, 1071, 6116, 5455, 943, 160, 6827, 2539, 3312, 2104, 501, 2974, 2408, 6422, 6474, 6829, 1593, 4996, 2659, 2391, 1915, 6326, 1219, 4100, 5878, 5848, 2317, 5319, 5202, 3973, 4375, 3918, 1163, 2750, 4406, 4482, 3495, 5789, 6987, 492, 4735, 5084, 2128, 1155, 6959, 5972, 2056, 3272, 6318, 2232, 3372, 2064, 1993, 3733, 3088, 3465, 6299, 680, 3816, 1731, 191, 19, 6084, 3969, 3112, 316, 1253, 2370, 2832, 439, 825, 419, 2565, 2708, 5885, 582, 4885, 6056, 1990, 3001, 378, 2398, 2679, 1678, 4929, 1965, 872, 6626, 6551, 2226, 4551, 655, 3413, 1154, 6625, 4159, 5020, 5403, 2972, 4001, 1233, 4295, 6350, 5219, 4869, 901, 4340, 2481, 5145, 3954, 3544, 2477, 6660, 831, 3677, 3366, 6662, 2478, 6160, 5039, 6281, 3046, 4934, 5449, 6035, 5005, 5900, 4982, 3249, 2571, 5773, 2915, 1930, 3145, 5354, 5094, 4390, 4865, 905, 2883, 2804, 2809, 1981, 4171, 6135, 6861, 1614, 2263, 626, 4618, 3125, 6245, 2178, 1776, 272, 3854, 4304, 1863, 4863, 804, 1207, 4895, 95, 4399, 6416, 1369, 4325, 1265, 4660, 3398, 5562, 359, 5612, 267, 383, 6580, 3693, 5864, 4777, 4036, 519, 1520, 3924, 4663, 3959, 2336, 3753, 813, 1321, 2043, 2278, 3400, 3535, 5195, 6604, 5528, 4860, 3580, 4198, 3841, 1844, 2039, 6518, 2219, 2268, 5462, 6808, 5338, 3334, 5459, 5015, 2850, 6812, 5781, 2340, 69, 5495, 5475, 3070, 4606, 5776, 203, 4109, 6792, 619, 5230, 5465, 2314, 1578, 1779, 682, 5707, 265, 1367, 1170, 4381, 6472, 852, 183, 504, 3655, 1101, 5555, 1700, 5518, 3791, 3350, 3557, 3480, 5960, 2550, 3364, 4213, 868, 3358, 2580, 1109, 4247, 81, 2117, 5139, 3191, 5644, 6263, 1675, 4866, 5282, 2991, 5899, 5626, 6761, 5788, 2829, 506, 2875, 3134, 4253, 3627, 5257, 13, 6067, 2805, 75, 4084, 2080, 5544, 4684, 5444, 4273, 6774, 2021, 5488, 5926, 4383, 4011, 5483, 923, 4710, 2664, 5940, 4145, 1743, 444, 6787, 5645, 1722, 5896, 1631, 2067, 5888, 6444, 3409, 5812, 3931, 5631, 1642, 2349, 548, 1741, 1306, 794, 3903, 5993, 89, 3424, 373, 6851, 2672, 5510, 629, 4070, 5347, 449, 339, 5581, 1625, 2686, 5792, 3641, 5074, 1734, 3581, 3904, 1492, 3902, 2681, 1721, 5443, 386, 3, 2848, 6000, 1149, 3089, 5725, 714, 1749, 6606, 6184, 4888, 4713, 76, 3767, 6589, 5174, 3832, 2277, 4974, 3631, 937, 4768, 3411, 3778, 5001, 4156, 751, 360, 3960, 5209, 5458, 2582, 1264, 4309, 3674, 615, 3574, 2244, 2634, 500, 2395, 2903, 6163, 5830, 4376, 1869, 510, 3422, 4699, 5043, 2204, 1736, 1701, 21, 828, 4244, 2144, 42, 2743, 2652, 1404, 982, 4072, 2746, 1049, 5120, 1848, 6636, 161, 1953, 6188, 4622, 3085, 1468, 3127, 4930, 2389, 4131, 4595, 2011, 558, 3934, 4059, 6497, 780, 1813, 2520, 3649, 1573, 641, 4125, 3464, 2193, 775, 4593, 678, 2510, 2674, 5411, 4173, 2425, 5473, 6676, 4809, 1950, 528, 1992, 5831, 6562, 4782, 2123, 5277, 225, 1920, 5089, 4430, 2345, 338, 5417, 3387, 2191, 4587, 3279, 1841, 5956, 3978, 2003, 4719, 1656, 1819, 527, 1465, 2195, 598, 4106, 4752, 3328, 1123, 5352, 5529, 4801, 2960, 3456, 5206, 4335, 3529, 2792, 4490, 1508, 3933, 22, 2354, 2868, 1348, 2036, 2888, 5598, 5494, 4021, 3488, 5684, 732, 5869, 1105, 3385, 3608, 3044, 2555, 2923, 2022, 6574, 3084, 5414, 3976, 3270, 4336, 974, 4846, 109, 6172, 2828, 2840, 5108, 3314, 5493, 6794, 837, 4225, 3559, 920, 2177, 4219, 4188, 6227, 4393, 4999, 916, 2063, 3282, 1455, 658, 2181, 3189, 3132, 3972, 4120, 2787, 6034, 4518, 2471, 6802, 4871, 809, 3599, 817, 6370, 992, 2641, 78, 1427, 4396, 5463, 640, 6658, 5585, 5112, 2624, 5121, 1450, 3483, 3897, 2156, 1602, 2041, 2956, 4107, 4346, 4718, 3283, 1955, 2628, 3147, 4633, 6775, 4077, 1849, 6071, 5524, 1168, 1658, 3074, 4711, 6225, 6578, 5642, 6365, 4321, 6769, 296, 3772, 4214, 5397, 4954, 4791, 4080, 2653, 6890, 308, 3053, 5678, 159, 4438, 2536, 3066, 5171, 3901, 3308, 3899, 588, 479, 1184, 6641, 5508, 3117, 4906, 3211, 4085, 6608, 3885, 5046, 1408, 6900, 4652, 3081, 1769, 3496, 1023, 2627, 1633, 6304, 2427, 6724, 2631, 4495, 5958, 4661, 3514, 6837, 6142, 5669, 6919, 4585, 2554, 3790, 3452, 4961, 2626, 5322, 3235, 3090, 3836, 3890, 3773, 5577, 322, 3562, 1175, 4250, 4970, 2534, 1473, 6530, 80, 5647, 964, 2372, 4060, 6081, 5413, 2944, 5320, 4369, 6368, 3777, 5479, 946, 3887, 878, 2583, 6639, 910, 6039, 753, 2643, 2607, 2597, 1475, 6897, 5520, 6779, 6485, 5817, 6804, 2751, 5787, 4440, 157, 1041, 5635, 3644, 4044, 5095, 1334, 5336, 3610, 940, 1560, 5825, 5355, 224, 3722, 4557, 5467, 3151, 2485, 1313, 2240, 5059, 1361, 1431, 3577, 1676, 5441, 6778, 275, 6750, 4665, 876, 1599, 2052, 3848, 2490, 4770, 6098, 4233, 195, 650, 2979, 3749, 929, 3911, 6150, 6522, 4384, 6295, 5770, 6388, 6880, 3310, 4915, 250, 4155, 5002, 1925, 6902, 5835, 5280, 2008, 1842, 925, 303, 6065, 2248, 277, 242, 2723, 5204, 3590, 4876, 599, 1831, 5651, 2230, 1698, 5936, 2432, 591, 3615, 1513, 731, 4951, 3646, 6275, 68, 3537, 1279, 1353, 4549, 4732, 5624, 672, 3857, 1181, 4742, 581, 369, 5138, 2780, 3861, 6913, 1587, 5870, 6762, 6023, 1480, 4474, 110, 6073, 3635, 1958, 4605, 2122, 6127, 4446, 1329, 3401, 2864, 6024, 6333, 5780, 5574, 5737, 2299, 6531, 5857, 63, 2224, 3883, 4475, 4623, 3040, 1697, 5383, 2457, 3744, 2443, 1204, 2145, 5889, 37, 4266, 5146, 6946, 5324, 2060, 6800, 6738, 1986, 496, 6969, 2535, 1515, 6822, 3671, 6546, 2192, 2680, 2146, 6930, 4248, 358, 6695, 5376, 2315, 892, 3213, 2590, 311, 6965, 2301, 4300, 6145, 2360, 5270, 4800, 2466, 2197, 3547, 2874, 2756, 1674, 739, 1043, 4464, 4717, 1451, 521, 3656, 6535, 2952, 3716, 4763, 1365, 6955, 2720, 6240, 4766, 864, 6078, 1750, 3306, 6313, 1247, 264, 4417, 2273, 1923, 5905, 6386, 5047, 3230, 5909, 6584, 5477, 2638, 5532, 1047, 1694, 6498, 4826, 5245, 1742, 3654, 5570, 1376, 4832, 1606, 5586, 1699, 5855, 547, 3329, 6438, 4310, 301, 1799, 1146, 5632, 5887, 2655, 6815, 3174, 6294, 2992, 5250, 5559, 3258, 2414, 2127, 4887, 1108, 3203, 5438, 6834, 2538, 4075, 3510, 5530, 6648, 4629, 2695, 2813, 3184, 2731, 2861, 6730, 2148, 6561, 4105, 407, 2125, 3680, 4918, 1275, 5950, 5757, 5461, 1456, 4588, 3467, 715, 5345, 4152, 171, 998, 4223, 5734, 170, 3386, 5247, 4520, 3492, 6383, 6757, 3521, 4194, 4998, 4849, 1927, 4817, 5538, 3285, 6743, 4040, 6269, 6891, 1888, 5052, 151, 2283, 3545, 3834, 4692, 5382, 5367, 3485, 5576, 1006, 2881, 499, 1868, 5363, 149, 4168, 4806, 5614, 6848, 6484, 798, 1973, 1966, 6221, 1940, 4389, 6013, 3818, 5484, 5222, 3640, 556, 4956, 6989, 5859, 3071, 2542, 3388, 5105, 5329, 1, 4532, 5511, 6958, 2770, 3460, 2404, 3166, 2943, 6961, 2865, 869, 2876, 5031, 3849, 950, 4465, 1653, 4373, 3010, 2179, 1099, 3237, 6728, 3347, 6007, 5775, 596, 4259, 1472, 1933, 2912, 4230, 2270, 3420, 1974, 3357, 2546, 1723, 2396, 4611, 4463, 793, 5641, 6673, 3542, 5268, 3135, 5727, 6234, 3222, 3605, 5361, 5535, 1180, 24, 86, 5149, 3143, 4964, 1271, 4676, 3457, 154, 3515, 5840, 1022, 6363, 306, 6259, 2433, 3752, 1684, 3227, 3585, 5749, 1225, 4181, 5266, 1785, 6564, 1914, 2405, 5194, 3952, 1727, 324, 5850, 1009, 800, 663, 4055, 1403, 4016, 1883, 1137, 6192, 5534, 4007, 2030, 5092, 746, 3553, 6324, 4897, 132, 1717, 5590, 4533, 3619, 4566, 6623, 1591, 2856, 2941, 3428, 4536, 5798, 529, 4292, 1420, 2591, 5182, 6865, 4135, 493, 5731, 3824, 2212, 2308, 4119, 3602, 5616, 6274, 6995, 6595, 1255, 3259, 3430, 5311, 5148, 3548, 341, 6685, 6954, 2119, 2866, 5115, 1775, 5087, 6957, 3002, 3302, 3300, 350, 2472, 4149, 6571, 5067, 3673, 2665, 6357, 1911, 3929, 5970, 1999, 4068, 1546, 3182, 285, 3029, 4431, 5038, 3745, 3295, 3951, 1969, 5826, 1072, 3287, 2304, 4679, 4844, 463, 3374, 3661, 3068, 5658, 5531, 199, 1660, 6487, 627, 1141, 5733, 4744, 2764, 6305, 2968, 6213, 5563, 4723, 1922, 911, 5258, 2818, 5990, 5159, 1016, 2958, 1509, 2361, 4512, 1913, 4864, 6032, 1705, 3520, 422, 471, 884, 6825, 6195, 2834, 1852, 981, 6288, 469, 4653, 6534, 2310, 1150, 834, 6499, 6058, 51, 1617, 6678, 1077, 5698, 6351, 2996, 6655, 4287, 3982, 2760, 6758, 3989, 6885, 5911, 5921, 5827, 4428, 12, 5377, 4029, 5453, 4407, 4751, 5405, 2112, 2800, 1664, 2706, 2900, 5325, 3382, 4816, 6820, 6400, 1067, 3586, 1469, 2387, 6771, 4141, 6338, 5373, 4612, 4613, 1791, 4140, 3732, 4034, 5457, 6918, 4859, 597, 5660, 6840, 2445, 5873, 5331, 1746, 1792, 6315, 4061, 2205, 4382, 700, 218, 116, 6283, 2455, 1282, 3478, 821, 2867, 1850, 6292, 6162, 3228, 5927, 1908, 1315, 1765, 1854, 167, 2807, 2898, 4765, 3487, 1018, 1197, 1434, 2305, 5221, 4950, 3688, 2441, 890, 4142, 5284, 2650, 4412, 357, 450, 1885, 278, 1499, 1865, 125, 1948, 5662, 1655, 4830, 4342, 4067, 2200, 189, 1375, 4294, 4610, 1460, 3336, 1142, 4580, 719, 1875, 6973, 2359, 5070, 6461, 3429, 4977, 3406, 4113, 3691, 2048, 1638, 6628, 5928, 3775, 2630, 6320, 3604, 963, 5743, 1665, 3549, 4797, 1890, 440, 4901, 2183, 4510, 6675, 3005, 4359, 6341, 6479, 3426, 2772, 1957, 1954, 5060, 1194, 6018, 5316, 29, 4329, 2463, 281, 3945, 5655, 4308, 6882, 3618, 364, 2646, 1157, 4793, 4278, 6507, 3720, 2065, 3451, 532, 4056, 2105, 3443, 6287, 2250, 2793, 2023, 2393, 6912, 1246, 3433, 2070, 1425, 1355, 4228, 4688, 2399, 5630, 5761, 5949, 3360, 5429, 6690, 2323, 6637, 867, 5916, 4822, 3233, 6316, 5359, 3028, 4356, 2284, 5881, 200, 5706, 2093, 6223, 3837, 1511, 3519, 6156, 5863, 1054, 5272, 6391, 1371, 1014, 2502, 6095, 4596, 838, 1406, 6505, 1943, 3996, 2363, 1632, 5402, 1394, 6334, 4879, 3193, 5758, 3874, 2076, 2909, 1121, 5388, 4442, 4331, 6143, 3800, 6872, 6938, 1421, 6810, 4756, 4802, 2142, 6290, 3155, 1310, 219, 2623, 6101, 6786, 576, 6301, 4419, 945, 3995, 4703, 2162, 5876, 5217, 1751, 3825, 3120, 6850, 263, 317, 885, 1040, 131, 1059, 6677, 6753, 895, 3243, 1283, 3407, 1308, 6174, 6805, 2388, 6437, 6426, 388, 2957, 726, 5291, 6445, 5699, 3416, 5637, 6528, 163, 854, 3927, 6683, 5791, 3038, 2239, 3812, 6417, 2617, 394, 4955, 5314, 6, 1977, 2106, 1541, 2971, 3940, 5223, 5144, 4780, 4128, 4971, 6403, 3200, 1342, 1030, 2584, 3762, 771, 1576, 4436, 1232, 3115, 485, 1256, 4516, 3072, 4427, 5164, 5226, 952, 2753, 268, 3501, 3286, 4767, 6899, 5315, 5058, 3650, 2140, 3653, 3130, 6087, 4726, 5705, 284, 2970, 6979, 4291, 5941, 6877, 5567, 593, 58, 2562, 1280, 6718, 5796, 1982, 460, 166, 1140, 6280, 4733, 1062, 2619, 2133, 5995, 4215, 3229, 4025, 5180, 3628, 5744, 2885, 1959, 6212, 6745, 4513, 4706, 234, 4607, 5188, 4293, 5340, 887, 4757, 4769, 3639, 5056, 2926, 4392, 1273, 428, 2174, 997, 5971, 6816, 3047, 5390, 4261, 2670, 3889, 2935, 1714, 4371, 4538, 6247, 1224, 3150, 4177, 1840, 1884, 4226, 3864, 4944, 4976, 3042, 4006, 3144, 3811, 4649, 6134, 2118, 3754, 2600, 6832, 4063, 1567, 5502, 5103, 1118, 6931, 3760, 5068, 2919, 2272, 3266, 2344, 3121, 3309, 2945, 2913, 204, 6478, 1843, 6721, 6182, 2059, 4883, 2769, 1114, 5362, 2663, 307, 3271, 1686, 6501, 193, 2682, 4470, 1366, 5113, 2355, 4426, 1441, 5071, 6857, 2579, 6159, 1942, 1343, 3379, 1347, 5096, 5646, 953, 2983, 4462, 567, 4893, 4134, 1422, 102, 3157, 1597, 2567, 1530, 4572, 2496, 742, 6139, 6826, 4521, 6348, 4316, 1709, 935, 579, 4563, 4099, 1542, 5603, 815, 5670, 302, 6094, 5877, 2740, 2045, 6669, 5951, 5042, 4648, 4560, 2728, 632, 1294, 298, 1669, 2508, 2220, 3177, 2563, 3957, 5237, 6746, 6406, 389, 3459, 4088, 4235, 379, 1766, 4840, 1803, 1707, 6153, 1096, 2006, 2412, 730, 728, 2833, 4672, 1463, 6254, 2948, 1066, 1454, 2276, 4987, 3188, 1128, 5992, 4941, 6572, 3774, 5657, 6376, 3163, 5822, 3263, 2483, 1021, 4541, 933, 3418, 5024, 6424, 3759, 6020, 1860, 2836, 3938, 2151, 5768, 5437, 4877, 1430, 4644, 1098, 669, 896, 101, 2698, 2290, 1589, 6767, 5875, 5166, 1980, 5566, 84, 1554, 723, 2316, 5201, 5190, 6708, 4873, 2413, 6099, 6347, 424, 4227, 6251, 2484, 6824, 3288, 2596, 6217, 28, 4514, 2855, 3160, 153, 2364, 472, 6797, 34, 4912, 561, 2918, 1968, 5032, 1964, 5600, 3770, 4882, 3833, 3998, 2620, 6415, 5154, 656, 6113, 2911, 3965, 2287, 3367, 5867, 3311, 1585, 1106, 2644, 6814, 701, 3847, 1111, 1011, 1449, 6140, 5298, 5794, 1521, 1200, 853, 2103, 2671, 5898, 446, 1845, 2566, 932, 928, 3783, 5882, 5890, 6635, 5745, 6399, 6552, 155, 6489, 5077, 249, 4502, 4018, 1626, 172, 1787, 3632, 1637, 1162, 1291, 1384, 4416, 4437, 4420, 6839, 6892, 323, 6766, 6339, 785, 30, 2929, 2313, 1607, 1693, 6248, 2196, 2777, 1243, 3014, 4626, 1085, 4542, 315, 5366, 2446, 5595, 5469, 657, 783, 33, 1029, 4452, 6711, 1093, 3766, 2707, 3634, 6532, 6972, 5937, 849, 5536, 1268, 3651, 4086, 5913, 3079, 2694, 1199, 259, 1563, 4896, 1017, 2465, 3069, 1005, 3787, 6622, 1172, 4154, 5552, 1380, 48, 5915, 2851, 145, 3097, 3589, 633, 1317, 6666, 6002, 2406, 4337, 6593, 4274, 3907, 6483, 5517, 1203, 6264, 4162, 5025, 4507, 764, 4948, 5924, 2401, 2688, 4137, 587, 2778, 3027, 1798, 5629, 4965, 6440, 2436, 2846, 1092, 4241, 3690, 5317, 941, 254, 3161, 705, 2430, 2930, 677, 2079, 3728, 5649, 3207, 1724, 628, 2870, 2096, 3670, 3893, 4655, 5407, 3802, 6653, 3225, 3262, 1892, 6155, 1612, 777, 4546, 4926, 3220, 6327, 4504, 5720, 2171, 3039, 1569, 5394, 4527, 4208, 2524, 855, 3827, 5609, 741, 6381, 2872, 4319, 6640, 1681, 5153, 3970, 827, 2134, 4019, 2965, 839, 4667, 5097, 188, 3096, 6715, 3730, 5259, 1500, 1000, 441, 3840, 3415, 1496, 2068, 395, 18, 5203, 706, 1688, 3086, 2501, 5177, 3820, 4122, 930, 4526, 5492, 2210, 5141, 1254, 3343, 459, 1644, 737, 944, 4339, 211, 538, 1497, 6228, 6177, 118, 5716, 6776, 6068, 5421, 1356, 5283, 1363, 1035, 3613, 6051, 2649, 1516, 3446, 5525, 4824, 2786, 1851, 1461, 4686, 689, 5584, 2687, 3064, 2044, 2255, 3108, 1773, 3093, 2677, 6151, 5233, 5179, 5980, 584, 1649, 370, 4301, 2802, 1386, 3964, 6649, 2606, 4910, 4450, 6052, 2082, 977, 133, 736, 6202, 5420, 5565, 6587, 1762, 6686, 1827, 2164, 6332, 1873, 127, 2423, 1867, 1501, 4078, 3805, 1704, 1577, 2549, 1453, 229, 332, 5697, 2917, 1864, 1119, 5607, 758, 4453, 1646, 2725, 3905, 3493, 179, 4650, 2031, 4600, 6566, 2071, 1396, 3967, 989, 856, 5239, 2878, 4530, 6853, 5557, 4815, 4032, 6014, 3977, 5575, 1057, 6026, 5227, 5823, 3884, 331, 5718, 3517, 5212, 4681, 1269, 2950, 6981, 2797, 4578, 1987, 6232, 4778, 1278, 6132, 1007, 1322, 1550, 6760, 5261, 3049, 5301, 4592, 6783, 4290, 2589, 509, 513, 1988, 3277, 6694, 1171, 147, 2225, 6375, 3353, 1505, 3362, 654, 1307, 557, 4861, 6868, 912, 602, 3946, 5196, 6001, 4000, 3804, 1872, 2814, 595, 5378, 5611, 4445, 1471, 0, 3078, 3352, 5083, 3245, 6043, 6473, 177, 2560, 6413, 6414, 792, 6367, 3869, 2645, 3992, 325, 955, 4277, 1809, 5742, 4517, 4328, 1236, 5028, 4833, 4360, 1833, 3454, 4004, 5604, 5110, 6021, 630, 5503, 2269, 6756, 3035, 2358, 4184, 2896, 2252, 6819, 2661, 1044, 3437, 5186, 5054, 2101, 3404, 3708, 4730, 5454, 2097, 6811, 2150, 2346, 1603, 757, 4433, 1835, 49, 3065, 3338, 2497, 6734, 6256, 565, 4774, 6464, 2939, 3265, 1392, 2882, 2700, 4795, 1737, 5578, 4619, 6697, 962, 505, 248, 5321, 5187, 3536, 5756, 4685, 620, 2229, 5385, 483, 1780, 5594, 3393, 6914, 1855, 5851, 222, 2357, 4377, 4755, 414, 3826, 614, 4750, 1042, 2089, 6158, 5753, 5892, 6106, 1340, 1274, 3914, 4914, 5181, 4531, 1695, 175, 6211, 1251, 2351, 5816, 6463, 3378, 2689, 2291, 2160, 5954, 3667, 1286, 2087, 6218, 3539, 2873, 1437, 6079, 2418, 2727, 6201, 2953, 6616, 4313, 3251, 209, 4599, 6971, 348, 5365, 3291, 1732, 3522, 6842, 4761, 1277, 6838, 35, 3136, 5496, 1543, 879, 1230, 4220, 3685, 1464, 1881, 4341, 4854, 4460, 6138, 3736, 5615, 4993, 6709, 4725, 647, 5130, 2318, 6360, 6830, 5648, 10, 2335, 2495, 27, 1309, 2717, 1174, 1805, 6271, 1486, 4394, 5252, 1164, 6986, 735, 4391, 6235, 5200, 552, 2621, 2111, 2132, 2002, 712, 5886, 6103, 4616, 1238, 3399, 3913, 2469, 4787, 3218, 5813, 2504, 6241, 6915, 111, 1135, 3595, 6086, 4594, 2946, 135, 1476, 2342, 5263, 3337, 2969, 5189, 2057, 1078, 6451, 6749, 1715, 5769, 5929, 1781, 3896, 5643, 1258, 6447, 3678, 6215, 3116, 2500, 2783, 4471, 6515, 2693, 401, 3601, 3712, 562, 5127, 2143, 1979, 87, 6618, 3979, 6273, 1466, 236, 5381, 5036, 4577, 5671, 4847, 5399, 4707, 423, 3168, 6394, 873, 1797, 5729, 951, 5845, 2241, 5715, 6984, 2434, 1188, 2055, 4124, 1667, 5235, 6735, 6384, 534, 6878, 2470, 2779, 637, 474, 3317, 5597, 3930, 5147, 1276, 5090, 299, 1912, 961, 2949, 6500, 6482, 1373, 6407, 6541, 2938, 5917, 181, 1252, 4444, 5842, 1132, 2757, 2963, 5409, 2845, 2685, 624, 1866, 5634, 1596, 4190, 5482, 5663, 2937, 1372, 2295, 2773, 3181, 6296, 202, 3942, 1687, 4272, 5664, 6716, 5323, 5275, 1728, 92, 1115, 5619, 699, 5999, 516, 738, 2341, 1143, 2202, 1244, 4022, 345, 4989, 1487, 6175, 4487, 260, 6605, 716, 2155, 5424, 1976, 5945, 3273, 6990, 907, 2312, 2289, 3997, 6599, 2467, 1338, 3578, 6594, 6293, 2507, 3033, 4002, 810, 4307, 708, 3990, 6939, 4501, 2737, 1086, 969, 721, 685, 6209, 4741, 5334, 5013, 4164, 3138, 5948, 6849, 5049, 4178, 2237, 4569, 1027, 5073, 5197, 2246, 3984, 781, 9, 276, 2920, 2329, 1195, 2789, 1133, 859, 4556, 4447, 5251, 2383, 3948, 238, 4046, 455, 2993, 402, 702, 130, 1046, 779, 5472, 141, 762, 1113, 6359, 2709, 1545, 4132, 2233, 2558, 2302, 2382, 3530, 6523, 5151, 508, 140, 665, 2159, 1559, 5571, 3701, 3983, 4727, 606, 1191, 4385, 5623, 3853, 1004, 6975, 3192, 5131, 5014, 3006, 1402, 1250, 4017, 1523, 1998, 4033, 4024, 5273, 1836, 2614, 5985, 967, 5883, 4943, 1147, 4838, 5819, 3186, 4413, 2454, 687, 1917, 4480, 3592, 1208, 4789, 6529, 6906, 2449, 3109, 6450, 232, 3009, 5100, 3894, 2890, 4117, 5026, 2755, 6186, 2326, 1445, 3102, 4544, 2632, 984, 321, 6726, 4157, 6867, 1357, 6066, 99, 4127, 4709, 5910, 2578, 5934, 194, 6088, 4183, 6559, 6382, 3171, 221, 2525, 1479, 2921, 646, 4691, 3626, 3622, 3114, 1378, 3739, 6569, 4773, 2683, 1058, 2348, 1429, 5685, 3164, 2827, 5710, 2439, 6992, 3506, 1125, 197, 4397, 5224, 6194, 3472, 1318, 6647, 3835, 6821, 5983, 2353, 5805, 6613, 3975, 297, 3341, 6191, 1187, 178, 3170, 3516, 6392, 1395, 6312, 3158, 6533, 4508, 568, 5748, 5285, 2327, 1907, 5834, 6952, 2995, 4687, 5063, 6302, 3345, 6216, 3204, 494, 5618, 3900, 559, 2517, 2306, 5215, 4066, 4065, 1013, 980, 4853, 6964, 841, 5683, 1241, 1763, 1061, 5474, 6610, 4721, 5487, 1804, 5086, 6544, 4678, 555, 5489, 755, 304, 3784, 5661, 184, 6894, 3172, 3962, 3375, 2152, 3705, 3763, 4720, 4811, 549, 8, 2657, 354, 217, 3616, 6144, 3508, 5931, 1558, 4448, 6171, 572, 5118, 857, 1388, 1414, 3159, 6692, 5667, 4995, 330, 4662, 2042, 6047, 4666, 2374, 2925, 3617, 1349, 6053, 3597, 1673, 4829, 4601, 5326, 4589, 4094, 4570, 2274, 553, 4254, 2473, 2066, 6982, 1972, 4150, 3789, 4571, 4008, 1227, 454, 293, 999, 2294, 2280, 6705, 2365, 4126, 1880, 6224, 3500, 6920, 918, 759, 1457, 5260, 638, 919, 6080, 3260, 971, 1745, 3037, 5688, 3246, 4657, 5168, 6110, 5447, 3024, 5418, 4257, 6493, 3504, 5242, 4737, 5676, 1216, 4627, 4783, 3221, 2347, 4736, 5419, 5838, 5728, 2421, 6490, 2816, 2540, 6554, 4496, 1478, 1583, 3095, 5747, 6788, 1330, 2444, 1333, 5140, 5904, 1145, 1389, 5348, 4483, 173, 5997, 5766, 4957, 5784, 797, 5101, 6325, 5085, 6050, 1910, 1470, 5732, 4523, 6373, 3361, 3528, 283, 6446, 4357, 5295, 1522, 799, 2637, 6719, 476, 372, 4493, 4894, 4747, 4081, 1012, 4590, 3149, 4318, 6396, 4499, 3560, 958, 4268, 6352, 520, 56, 5771, 6948, 2377, 5021, 4265, 6199, 3183, 4519, 3696, 4275, 2288, 6517, 4645, 6699, 1088, 4659, 1771, 2005, 4352, 1031, 3335, 2461, 4009, 2027, 1185, 6693, 826, 3706, 4243, 3274, 186, 3727, 5901, 5998, 6409, 2235, 1608, 4361, 6577, 6854, 5774, 3958, 6941, 4714, 2050, 942, 4813, 5114, 6682, 6642, 3878, 5967, 1876, 4303, 4597, 398, 6205, 6656, 2451, 6876, 349, 3119, 5925, 4047, 6550, 546, 5541, 6055, 5933, 6763, 105, 6909, 3141, 2081, 4193, 1691, 1411, 5088, 2826, 1442, 4917, 2025, 2343, 5721, 4298, 187, 5312, 6185, 421, 6592, 6643, 1531, 2440, 2186, 763, 2007, 6614, 2978, 2869, 3663, 2493, 507, 2366, 380, 886, 2553, 4923, 2810, 4641, 934, 5416, 5163, 970, 698, 3502, 3591, 4535, 6963, 3683, 4753, 1733, 4043, 2599, 4245, 5908, 6462, 3985, 2910, 6807, 3395, 1484, 261, 697, 1082, 464, 5501, 3779, 489, 2880, 6727, 2037, 5412, 4682, 5802, 3756, 3932, 6575, 3355, 2492, 2733, 5551, 2962, 1156, 6118, 5098, 5964, 5696, 2522, 6495, 4489, 914, 4973, 326, 3327, 5989, 3785, 5847, 6983, 2593, 1483, 1110, 5636, 6722, 2790, 5339, 5509, 4051, 1800, 3421, 4180, 2207, 5515, 4103, 560, 6869, 6680, 2324, 4264, 1783, 1735, 2774, 3877, 1921, 437, 6809, 6060, 4574, 3450, 3665, 4013, 6519, 5192, 5777, 4907, 1032, 4175, 1458, 4139, 6448, 93, 3963, 3402, 6796, 6704, 6428, 6255, 4947, 3489, 600, 6059, 1364, 5050, 2137, 4903, 5391, 467, 617, 6870, 4796, 3439, 96, 3704, 3994, 4129, 4884, 176, 5708, 2916, 2879, 2615, 1518, 4217, 2817, 4497, 4091, 6257, 3810, 2871, 4083, 1899, 1037, 5016, 5874, 1186, 4586, 1034, 4362, 1028, 2605, 347, 1795, 5994, 2325, 3075, 3111, 3113, 3445, 5608, 740, 863, 2568, 2422, 3059, 4969, 1897, 1818, 4323, 4620, 6582, 3196, 5846, 2286, 2018, 5030, 2474, 956, 2812, 2886, 6022, 5460, 3838, 2648, 6793, 3692, 2678, 5955, 3094, 788, 3584, 1301, 4850, 3391, 1358, 3768, 6133, 1877, 2350, 4343, 328, 6818, 5048, 6538, 1053, 5079, 4979, 1368, 1198, 1281, 6527, 3781, 5713, 6903, 6246, 2544, 1898, 2521, 1857, 1080, 5271, 6193, 4565, 3936, 3909, 3318, 1436, 4617, 2612, 670, 2218, 5836, 3427, 3999, 4324, 3123, 4925, 5717, 3725, 3607, 3234, 468, 3823, 14, 4548, 4841, 2931, 2475, 3043, 5703, 4677, 2901, 1416, 1814, 4189, 137, 570, 3438, 2511, 5809, 5229, 3740, 4632, 1834, 1390, 3717, 1666, 231, 2450, 1565, 2394, 5387, 2934, 1740, 5996, 2761, 2766, 5736, 3156, 5364, 5126, 4258, 2012, 2998, 2296, 2776, 3633, 3941, 4486, 5602, 1652, 1094, 2172, 4435, 6250, 2984, 4302, 5356, 481, 6488, 1112, 4461, 2062, 3925, 659, 881, 6651, 2279, 1895, 1202, 2781, 6033, 3148, 6122, 6069, 3987, 1298, 5293, 256, 6154, 2032, 1945, 4378, 1325, 3815, 3928, 1556, 2908, 3554, 1341, 1538, 6733, 3718, 2530, 5790, 2332, 5143, 4902, 1535, 6710, 4170, 4410, 2533, 1295, 577, 1878, 1561, 776, 4285, 5162, 4121, 5170, 36, 2808, 4216, 6356, 6823, 2251, 2569, 4598, 2973, 1448, 4669, 2988, 4358, 4035, 6601, 2528, 692, 2719, 4058, 1760, 1120, 3576, 4804, 4972, 6220, 4748, 6006, 6646, 5062, 3080, 2238, 6806, 2194, 6970, 3974, 750, 1887, 5091, 3054, 4874, 2837, 5724, 6436, 4937, 5019, 902, 2985, 3871, 5943, 124, 4251, 2515, 862, 959, 3016, 6010, 1874, 2091, 90, 835, 1739, 1903, 631, 5410, 6393, 679, 2795, 300, 5991, 1235, 1257, 2588, 4819, 4511, 4262, 290, 2182, 1159, 1627, 1336, 4776, 5161, 4432, 6707, 5666, 3600, 1237, 5546, 3332, 2889, 4187, 4454, 5672, 5369, 4867, 2384, 6768, 4076, 2292, 435, 5981, 6565, 2217, 2884, 6004, 1823, 6456, 4345, 6737, 4409, 3290, 1303, 6385, 5470, 3087, 5589, 1952, 5625, 5963, 4206, 1609, 2713, 2696, 1604, 5856, 2029, 5313, 3197, 391, 1008, 91, 6847, 5029, 1260, 6114, 2209, 6884, 4477, 6176, 5592, 3844, 2961, 6852, 5795, 5665, 1824, 2839, 6765, 3073, 3648, 6910, 6536, 639, 4281, 2176, 2498, 3892, 1297, 3167, 2788, 6999, 1158, 6430, 1443, 136, 3988, 5360, 6813, 5722, 3060, 805, 1756, 6314, 2537, 3865, 5408, 1426, 6149, 2261, 5549, 3299, 1517, 4232, 3292, 4503, 3919, 2260, 3659, 2732, 4935, 6028, 4539, 452, 3859, 1039, 2038, 988, 3638, 4715, 6349, 6089, 5550, 4367, 3394, 636, 807, 1938, 814, 3831, 6096, 5512, 4927, 720, 1647, 2636, 2902, 3944, 1075, 975, 377, 6908, 4203, 4424, 4045, 5309, 3061, 979, 1462, 1944, 2293, 3694, 4924, 5601, 2047, 5897, 1261, 4562, 4522, 972, 5767, 2321, 488, 2167, 3236, 1519, 5057, 1817, 3475, 3077, 367, 2505, 6921, 6717, 1065, 4734, 4643, 6358, 1963, 6307, 2228, 400, 948, 5150, 1879, 3872, 3376, 247, 3568, 274, 5205, 6244, 4195, 5423, 2307, 5499, 1331, 3129, 6074, 5652, 4870, 266, 4798, 4673, 3866, 3645, 3830, 3199, 2468, 6230, 1967, 5537, 442, 4784, 5213, 6791, 4123, 3555, 2376, 1548, 724, 833, 3503, 6573, 4104, 5935, 1971, 4680, 3224, 5167, 1985, 5122, 544, 6130, 2135, 3194, 4169, 6157, 530, 3436, 3315, 1956, 1572, 253, 3434, 6411, 2629, 939, 5061, 5008, 2486, 6243, 291, 1189, 6932, 6904, 524, 2718, 2758, 6503, 3993, 410, 6663, 2611, 329, 3566, 2069, 5246, 6041, 4204, 4311, 4604, 5514, 3442, 1810, 5759, 2098, 6687, 6166, 5837, 6124, 927, 512, 3675, 4374, 5253, 85, 2265, 2860, 1671, 5173, 4683, 3534, 3267, 6579, 6427, 3684, 847, 1861, 368, 5358, 5613, 6453, 2491, 1929, 5337, 3217, 6210, 1536, 6547, 6836, 2977, 4472, 4425, 5165, 5134, 6879, 3579, 1595, 1354, 5832, 6723, 314, 1502, 3606, 4201, 2367, 4573, 725, 4938, 5243, 5386, 3232, 3319, 4138, 5033, 3281, 6929, 4092, 5176, 3326, 3473, 2763, 4875, 1393, 580, 1829, 3776, 2907, 6279, 4781, 4913, 5582, 2019, 1081, 5764, 3809, 3747, 6178, 5393, 5561, 361, 1778, 6397, 5906, 5922, 5839, 1231, 761, 4690, 2243, 134, 5719, 2759, 4722, 4704, 1398, 4754, 3242, 282, 768, 2253, 6017, 1432, 4698, 3447, 1192, 2222, 2697, 4940, 1828, 6457, 6654, 3322, 2893, 4498, 5961, 4111, 2784, 3550, 2838, 3676, 4012, 1019, 5306, 2639, 1553, 3082, 2000, 5694, 3110, 747, 2951, 601, 66, 2541, 3293, 6645, 604, 2437, 6306, 5675, 1262, 2016, 269, 6886, 3707, 4628, 5772, 6665, 846, 6916, 6189, 408, 4401, 6923, 6465, 5335, 4708, 3380, 1932, 3490, 1239, 1428, 3494, 6323, 45, 4338, 4366, 5828, 1214, 1210, 1846, 3780, 205, 1249, 5304, 1288, 5305, 543, 312, 3365, 4306, 5346, 1196, 6911, 3807, 4090, 6714, 1087, 4552, 2480, 5228, 2914, 4355, 3876, 3036, 4792, 4423, 5894, 5505, 5160, 4052, 517, 374, 6277, 1209, 5124, 4810, 6570, 2409, 4642, 122, 287, 3390, 3751, 1754, 754, 6960, 4218, 1768, 1978, 4991, 613, 3509, 245, 3076, 803, 4404, 1289, 168, 4005, 6725, 635, 5966, 1764, 4772, 2822, 4202, 3723, 4057, 1267, 3755, 1069, 5687, 2462, 5880, 2947, 2715, 871, 2843, 743, 2955, 3425, 4054, 2724, 2482, 2863, 4238, 1757, 65, 4820, 3863, 1581, 610, 2690, 6752, 5677, 5107, 1994, 5389, 535, 1311, 4843, 802, 994, 5820, 6077, 960, 4936, 5111, 144, 583, 3140, 2015, 3165, 4579, 2586, 6591, 733, 119, 213, 748, 2320, 198, 674, 3572, 6846, 4073, 4297, 1685, 215, 4524, 704, 6977, 1566, 1941, 1400, 445, 1961, 16, 4429, 6993, 2173, 4908, 4807, 1782, 4959, 6085, 458, 4492, 1327, 5294, 425, 957, 381, 2712, 668, 6421, 875, 397, 5075, 41, 5656, 4379, 6698, 417, 4764, 603, 4443, 112, 5891, 2592, 6090, 4212, 6798, 2020, 3139, 851, 3738, 2964, 6712, 5342, 3814, 251, 4191, 5401, 1796, 2548, 1382, 823, 922, 23, 4919, 6344, 5987, 660, 6164, 6207, 15, 6276, 2297, 6289, 2976, 1493, 1853, 3664, 6506, 1970, 2216, 432, 3146, 820, 2519, 502, 1815, 3216, 5374, 6378, 5281, 1896, 6044, 1716, 6460, 103, 1050, 4096, 1001, 2417, 1374, 6152, 6432, 4868, 4696, 1928, 5553, 2824, 1131, 6925, 1812, 5104, 830, 6943, 6991, 3657, 475, 622, 487, 1489, 2796, 4467, 3032, 4823, 3524, 6509, 5569, 5942, 1683, 3176, 1537, 4664, 6398, 2532, 6203, 4862, 3477, 551, 2371, 938, 3004, 4638, 2009, 6471, 3018, 6109, 6455, 5434, 3955, 3453, 2849, 515, 5183, 4878, 3187, 2897, 6019, 996, 5912, 1540, 2573, 128, 3966, 5357, 2794, 6331, 5137, 223, 4528, 4543, 2400, 2924, 3252, 6831, 5866, 405, 1477, 5797, 6214, 3882, 6204, 2028, 2821, 2407, 4231, 649, 4946, 3444, 909, 3323, 5344, 456, 2658, 858, 3513, 1703, 418, 3255, 2199, 5969, 1919, 3742, 2165, 393, 453, 6027, 3624, 6486, 2739, 152, 5450, 4945, 2967, 5172, 3397, 6696, 550, 5833, 6008, 392, 365, 571, 5918, 1248, 2887, 2576, 4210, 3238, 5249, 2397, 1784, 3254, 1744, 6222, 3611, 2259, 4101, 976, 2113, 4205, 2110, 574, 3008, 536, 1107, 6425, 6525, 778, 5102, 3808, 2744, 1532, 3063, 3482, 926, 3856, 1304, 3669, 1160, 1702, 4702, 3860, 503, 3625, 2223, 3851, 1610, 6703, 4049, 4842, 3666, 4909, 2603, 3786, 6137, 3758, 5638, 4625, 5372, 1166, 1584, 1074, 594, 5739, 2858, 5287, 5803, 40, 3497, 434, 4745, 210, 1452, 1946, 4646, 2157, 138, 5711, 6491, 1183, 6558, 5692, 2987, 334, 477, 1176, 2107, 6996, 4500, 806, 2936, 4851, 2247, 5430, 6681, 5879, 1514, 5440, 3764, 305, 2613, 1767, 666, 770, 760, 1677, 4200, 5506, 6863, 4509, 3571, 590, 4457, 2488, 5274, 2456, 1557, 427, 6603, 5841, 169, 3937, 50, 5808, 3275, 71, 1568, 6620, 1926, 148, 5451, 2765, 5539, 1344, 1629, 6238, 2892, 5404, 4279, 1352, 4582, 3935, 1882, 11, 965, 5303, 2311, 6621, 4738, 6470, 801, 3012, 61, 6387, 4348, 6147, 1165, 1234, 4144, 5296, 880, 6947, 1218, 3405, 6141, 3923, 5350, 6764, 2300, 5653, 5884, 5854, 3432, 1052, 3297, 5135, 589, 4992, 1482, 5668, 5583, 142, 1242, 4634, 1937, 216, 1002, 3316, 1316, 5012, 2187, 1692, 2402, 514, 3015, 1290, 2785, 4771, 5610, 2102, 3710, 5129, 53, 6161, 4456, 3668, 6671, 1806, 5289, 3011, 3801, 4621, 2975, 4, 6630, 883, 688, 5125, 4476, 6270, 1935, 2752, 1808, 1103, 2721, 4473, 3231, 3179, 5044, 865, 4916, 1003, 4095, 3729, 1097, 3126, 4899, 4962, 174, 1506, 6510, 1240, 6950, 2088, 722, 5704, 3304, 6355, 3821, 2206, 5445, 5852, 3342, 1588, 4402, 4614, 4038, 1605, 5521, 5695, 5800, 1639, 6374, 2130, 6402, 5155, 2054, 1300, 987, 789, 2180, 713, 1302, 1399, 6011, 3660, 438, 2381, 6330, 72, 2352, 5436, 766, 6119, 6667, 4700, 6187, 5621, 1346, 1713, 6494, 4182, 6219, 3083, 6790, 3699, 1906, 6131, 2503, 569, 6736, 3223, 4986, 491, 6706, 2094, 4608, 6265, 6364, 6117, 2667, 671, 3908, 6442, 2609, 5799, 6168, 2598, 5700, 1326, 1439, 2654, 3051, 4246, 3621, 6037, 4186, 2701, 55, 2256, 1391, 4561, 2168, 5726, 4668, 653, 4779, 5751, 3587, 6841, 6978, 100, 4172, 4731, 954, 4071, 4388, 3383, 5712, 4003, 6310, 1226, 4994, 4365, 4814, 1332, 3916, 607, 2762, 5930, 3339, 667, 6844, 3906, 5810, 5198, 4354, 6967, 478, 6308, 6968, 5579, 2572, 5278, 4143, 6652, 5977, 5351, 2328, 3873, 2499, 6303, 1488, 3449, 6102, 1179, 2523, 5431, 4296, 4315, 605, 1525, 5659, 6759, 6480, 3118, 836, 6598, 3609, 1645, 47, 4728, 4856, 973, 4249, 64, 5818, 2392, 1983, 243, 4980, 1383, 3858, 4788, 1598, 2120, 3195, 645, 3567, 2531, 6516, 6755, 6410, 2642, 5279, 5871, 968, 5308, 523, 1498, 5979, 4165, 3340, 533, 3067, 3703, 2989, 2126, 3381, 1825, 5395, 6282, 5962, 6475, 466, 850, 6229, 6125, 3471, 4363, 3573, 2356, 2380, 3746, 6751, 2564, 4469, 1320, 6664, 3348, 4224, 4222, 5923, 6634, 5244, 1575, 5426, 5755, 2982, 6513, 4694, 4163, 1272, 4689, 1984, 484, 1444, 3491, 6942, 3344, 5782, 769, 618, 5778, 4567, 2891, 2933, 3593, 5815, 2116, 158, 1725, 6672, 729, 6949, 6076, 1090, 6688, 5573, 4529, 1314, 4583, 2647, 2852, 5231, 3031, 2227, 3396, 5211, 5478, 6466, 94, 1847, 2419, 2543, 2086, 1010, 6702, 3806, 1622, 123, 1689, 6596, 2551, 3796, 4330, 5297, 6585, 6048, 6924, 114, 4398, 2841, 5018, 3062, 2078, 2138, 4263, 4082, 4197, 774, 5055, 5210, 5452, 1481, 6129, 3947, 3408, 2339, 1148, 3250, 270, 3106, 1245, 4110, 6200, 6835, 4758, 4286, 5466, 5218, 1635, 5824, 6860, 1178, 6729, 2575, 343, 5690, 3803, 3719, 2010, 3324, 625, 295, 3240, 2438, 6922, 1063, 5793, 2322, 2775, 5384, 1641, 4760, 6481, 5868, 462, 230, 6748, 1826, 5491, 2748, 4422, 5425, 98, 4351, 6233, 6856, 4305, 3846, 6286, 6568, 2131, 2905, 695, 4812, 1360, 808, 6777, 1562, 5952, 5178, 3583, 3797, 3264, 6619, 6795, 3048, 4064, 6657, 5862, 6336, 404, 4545, 82, 3466, 4658, 5617, 1661, 4221, 1774, 3463, 1100, 4449, 6126, 1726, 2791, 1102, 3714, 791, 6242, 5481, 6377, 4405, 1527, 4739, 214, 2820, 2282, 6732, 416, 4922, 6091, 2847, 5558, 6128, 1201, 2711, 1467, 1901, 5568, 6458, 6945, 4234, 1177, 6785, 2234, 767, 6181, 3499, 5547, 6180, 4280, 3922, 2281, 164, 5605, 2506, 77, 1405, 4675, 1459, 6366, 5017, 1494, 4647, 6549, 2625, 1654, 6895, 2940, 2927, 5654, 4167, 1104, 4146, 4805, 3190, 3239, 5318, 3307, 6469, 4174, 786, 5682, 1337, 2691, 1221, 749, 344, 2577, 88, 1832, 585, 1680, 4370, 2331, 26, 5872, 3794, 811, 4115, 4211, 6258, 2651, 5957, 1862, 3855, 6953, 4525, 5486, 156, 621, 2747, 6319, 4439, 5709, 1730, 3152, 6009, 5490, 6239, 4911, 6799, 3662, 2767, 703, 5123, 1127, 5396, 2986, 5829, 1729, 1544, 220, 4455, 2601, 1397, 752, 2662, 482, 6862, 2699, 1526, 3154, 3603, 3734, 4656, 5000, 3822, 3782, 2464, 2264, 643, 1711, 3523, 3269, 2842, 4615, 6936, 2635, 4949, 3412, 2024, 6600, 2602, 241, 773, 2479, 59, 3303, 6441, 2895, 1529, 6555, 318, 2458, 1083, 2254, 5580, 480, 5234, 1807, 4958, 2581, 3895, 2058, 473, 3417, 6553, 4255, 6700, 182, 5003, 2074, 3598, 126, 1616, 5593, 4242, 6253, 2100, 44, 1934, 664, 5199, 3026, 1643, 6874, 5132, 3829, 6934, 6070, 848, 3050, 676, 5286, 611, 983, 431, 906, 891, 1811, 6907, 1060, 6389, 3698, 1894, 5498, 6754, 870, 1129, 3917, 3162, 1217, 6873, 3679, 3799, 70, 2633, 6412, 6845, 2734, 616, 6353, 5763, 212, 3888, 4387, 4481, 3852, 5116, 2906, 244, 531, 691, 1485, 6165, 4981, 279, 1549, 661, 564, 4821, 3331, 3356, 5554, 384, 6998, 693, 4890, 5099, 294, 1991, 4062, 5119, 4695, 5976, 3041, 1893, 3757, 1995, 3056, 239, 4939, 5560, 433, 5959, 5216, 4015, 495, 3715, 4027, 5730, 816, 845, 1126, 5903, 6956, 5938, 526, 2460, 4441, 4701, 5265, 6773, 6521, 5256, 4400, 4317, 4288, 2529, 4459, 3569, 4794, 4759, 235, 5333, 545, 4386, 2149, 4857, 3949, 4494, 1417, 681, 3180, 4468, 4581, 4845, 3741, 3880, 1440, 1662, 106, 1821, 6962, 6390, 1328, 690, 6720, 5158, 6540, 1419, 1051, 4332, 2267, 396, 812, 2857, 4050, 4984, 4892, 6321, 2245, 5861, 5432, 1385, 6576, 4818, 3137, 6511, 6260, 6782, 5765, 1167, 6864, 3440, 537, 966, 5701, 2424, 4554, 6123, 709, 1124, 2275, 4603, 3939, 1152, 2334, 2904, 6542, 121, 5009, 2410, 3185, 6443, 1708, 3689, 498, 399, 97, 1215, 4968, 985, 1345, 2154, 1415, 6632, 413, 240, 2121, 5674, 1401, 2378, 5468, 6935, 3025, 6833, 3055, 4176, 3284, 6231, 784, 1891, 5307, 3481, 542, 6042, 4636, 2033, 6371, 5811, 2835, 4074, 3511, 6615, 4591, 6395, 3124, 208, 451, 6423, 4239, 844, 2333, 5156, 2516, 727, 6674, 2660, 2208, 3637, 1816, 1748, 915, 3551, 5, 2692, 4978, 6548, 6980, 150, 6108, 4705, 1628, 3294, 1720, 3697, 2994, 4785, 900, 2844, 710, 5633, 6345, 4630, 4835, 4276, 5522, 2997, 6029, 352, 4136, 5006, 1324, 6933, 3296, 5779, 6927, 280, 4712, 6036, 2198, 6104, 1223, 4967, 5596, 4547, 2211, 443, 337, 5895, 4988, 1413, 1190, 4749, 5741, 765, 6266, 5232, 1574, 3261, 563, 3441, 1623, 4403, 4069, 4693, 694, 4102, 143, 4421, 1091, 684, 67, 2705, 1663, 1619, 4740, 6261, 993, 31, 4889, 917, 6031, 3479, 1939, 192, 1139, 4028, 6928, 3103, 448, 3368, 43, 5806, 1634, 353, 6631, 2798, 2303, 3248, 1719, 2185, 6328, 718, 3455, 6496, 5944, 1837, 5523, 1679, 2385, 832, 6112, 6468, 3142, 5639, 6342, 518, 4836, 4147, 1084, 908, 420, 1949, 1379, 1287, 3461, 5939, 3702, 5762, 1387, 3104, 5965, 335, 5735, 5051, 4540, 2736, 662, 4953, 3798, 4118, 2771, 52, 5543, 1524, 1134, 2188, 3058, 5023, 3792, 7997, 7863, 7004, 7351, 7675, 7057, 7101, 7342, 7872, 7882, 7261, 7865, 7960, 7936, 7343, 7677, 7714, 7921, 7153, 7836, 7641, 7883, 7482, 7036, 7978, 7423, 7746, 7018, 7463, 7395, 7968, 7604, 7441, 7762, 7311, 7820, 7625, 7371, 7229, 7380, 7841, 7211, 7961, 7175, 7079, 7375, 7756, 7083, 7718, 7188, 7110, 7858, 7913, 7759, 7772, 7951, 7831, 7409, 7247, 7345, 7064, 7905, 7164, 7588, 7552, 7089, 7206, 7155, 7969, 7821, 7116, 7146, 7835, 7499, 7806, 7283, 7462, 7652, 7694, 7359, 7937, 7398, 7786, 7769, 7193, 7591, 7804, 7724, 7556, 7623, 7023, 7280, 7020, 7417, 7048, 7889, 7846, 7331, 7298, 7733, 7886, 7067, 7027, 7860, 7210, 7576, 7500, 7044, 7063, 7784, 7573, 7363, 7220, 7525, 7353, 7387, 7939, 7132, 7665, 7618, 7779, 7662, 7900, 7271, 7440, 7016, 7571, 7256, 7998, 7533, 7445, 7957, 7516, 7007, 7458, 7514, 7581, 7464, 7630, 7774, 7698, 7051, 7904, 7943, 7466, 7483, 7667, 7933, 7531, 7308, 7970, 7447, 7798, 7216, 7160, 7127, 7987, 7864, 7664, 7486, 7633, 7944, 7955, 7954, 7095, 7801, 7404, 7709, 7237, 7173, 7787, 7376, 7202, 7364, 7348, 7619, 7639, 7066, 7230, 7824, 7077, 7223, 7616, 7617, 7488, 7574, 7547, 7248, 7459, 7055, 7310, 7090, 7614, 7183, 7654, 7245, 7162, 7695, 7731, 7332, 7523, 7011, 7377, 7966, 7176, 7425, 7049, 7010, 7510, 7030, 7996, 7887, 7973, 7770, 7771, 7553, 7372, 7444, 7140, 7993, 7922, 7199, 7131, 7411, 7120, 7227, 7979, 7304, 7158, 7582, 7242, 7829, 7711, 7507, 7953, 7163, 7705, 7622, 7544, 7934, 7674, 7640, 7335, 7147, 7757, 7601, 7021, 7191, 7273, 7426, 7151, 7875, 7808, 7975, 7374, 7321, 7111, 7480, 7272, 7477, 7845, 7194, 7725, 7701, 7161, 7240, 7560, 7791, 7053, 7219, 7125, 7877, 7879, 7743, 7495, 7330, 7112, 7428, 7919, 7442, 7708, 7629, 7028, 7822, 7592, 7899, 7254, 7362, 7390, 7081, 7673, 7583, 7152, 7825, 7347, 7329, 7474, 7117, 7092, 7653, 7795, 7325, 7012, 7408, 7676, 7232, 7744, 7189, 7600, 7065, 7704, 7589, 7817, 7103, 7688, 7903, 7558, 7461, 7252, 7344, 7502, 7620, 7264, 7790, 7492, 7985, 7580, 7527, 7524, 7517, 7178, 7898, 7292, 7205, 7134, 7593, 7406, 7013, 7683, 7931, 7501, 7255, 7849, 7075, 7803, 7478, 7475, 7890, 7159, 7992, 7215, 7454, 7563, 7026, 7753, 7599, 7999, 7572, 7109, 7491, 7598, 7867, 7171, 7668, 7810, 7738, 7157, 7108, 7964, 7122, 7554, 7612, 7487, 7918, 7383, 7305, 7797, 7033, 7017, 7636, 7747, 7852, 7773, 7956, 7536, 7184, 7136, 7316, 7424, 7962, 7681, 7661, 7180, 7720, 7565, 7340, 7669, 7895, 7061, 7680, 7570, 7035, 7128, 7453, 7238, 7734, 7794, 7384, 7833, 7800, 7873, 7564, 7965, 7568, 7534, 7932, 7269, 7823, 7086, 7286, 7741, 7577, 7671, 7884, 7322, 7870, 7509, 7871, 7834, 7399, 7712, 7166, 7844, 7508, 7869, 7521, 7410, 7532, 7885, 7042, 7780, 7034, 7218, 7204, 7290, 7168, 7326, 7479, 7056, 7857, 7920, 7045, 7594, 7099, 7605, 7312, 7267, 7608, 7138, 7789, 7360, 7926, 7685, 7281, 7222, 7856, 7400, 7728, 7485, 7528, 7737, 7415, 7402, 7386, 7437, 7373, 7765, 7760, 7707, 7607, 7659, 7896, 7196, 7963, 7401, 7074, 7490, 7001, 7115, 7613, 7025, 7385, 7928, 7318, 7427, 7980, 7130, 7258, 7678, 7498, 7370, 7476, 7029, 7692, 7732, 7209, 7548, 7813, 7432, 7788, 7068, 7945, 7702, 7647, 7586, 7207, 7551, 7291, 7723, 7644, 7341, 7284, 7663, 7439, 7133, 7224, 7911, 7837, 7047, 7091, 7646, 7233, 7778, 7815, 7749, 7190, 7274, 7352, 7100, 7430, 7942, 7910, 7761, 7505, 7981, 7689, 7827, 7391, 7854, 7946, 7596, 7314, 7262, 7297, 7974, 7722, 7781, 7557, 7355, 7179, 7041, 7412, 7503, 7289, 7278, 7434, 7449, 7529, 7634, 7170, 7615, 7742, 7070, 7096, 7587, 7097, 7000, 7892, 7545, 7324, 7213, 7433, 7717, 7059, 7751, 7655, 7651, 7421, 7812, 7119, 7763, 7914, 7716, 7566, 7139, 7365, 7006, 7368, 7847, 7894, 7333, 7124, 7950, 7300, 7106, 7626, 7535, 7080, 7082, 7032, 7009, 7084, 7296, 7241, 7923, 7169, 7648, 7177, 7003, 7736, 7268, 7792, 7154, 7472, 7930, 7868, 7861, 7916, 7988, 7706, 7497, 7627, 7014, 7726, 7150, 7328, 7842, 7052, 7891, 7546, 7407, 7796, 7853, 7349, 7339, 7072, 7002, 7105, 7793, 7811, 7843, 7093, 7137, 7635, 7881, 7208, 7940, 7909, 7046, 7839, 7435, 7807, 7941, 7994, 7679, 7250, 7908, 7217, 7995, 7198, 7302, 7703, 7878, 7809, 7624, 7938, 7414, 7530, 7060, 7142, 7481, 7609, 7958, 7336, 7287, 7643, 7597, 7538, 7403, 7484, 7719, 7420, 7043, 7848, 7470, 7602, 7777, 7005, 7550, 7691, 7379, 7775, 7225, 7126, 7740, 7866, 7785, 7315, 7054, 7901, 7038, 7838, 7543, 7249, 7303, 7174, 7700, 7071, 7515, 7927, 7069, 7050, 7906, 7253, 7313, 7657, 7745, 7073, 7986, 7165, 7145, 7982, 7682, 7378, 7294, 7327, 7167, 7429, 7750, 7394, 7285, 7293, 7840, 7263, 7369, 7642, 7226, 7350, 7632, 7320, 7354, 7085, 7129, 7830, 7185, 7888, 7366, 7431, 7239, 7686, 7754, 7107, 7416, 7452, 7767, 7569, 7917, 7897, 7850, 7361, 7504, 7584, 7388, 7540, 7195, 7436, 7575, 7802, 7816, 7088, 7471, 7506, 7690, 7288, 7764, 7098, 7358, 7814, 7976, 7172, 7959, 7684, 7473, 7990, 7628, 7755, 7201, 7260, 7457, 7259, 7907, 7606, 7819, 7022, 7062, 7805, 7493, 7182, 7670, 7187, 7526, 7234, 7451, 7405, 7419, 7549, 7818, 7270, 7611, 7645, 7935, 7496, 7948, 7650, 7266, 7141, 7730, 7040, 7494, 7658, 7693, 7567, 7603, 7031, 7949, 7782, 7121, 7212, 7555, 7346, 7851, 7687, 7880, 7460, 7337, 7511, 7389, 7357, 7446, 7306, 7203, 7826, 7058, 7301, 7235, 7925, 7221, 7983, 7902, 7019, 7595, 7037, 7418, 7758, 7631, 7413, 7519, 7251, 7541, 7559, 7334, 7422, 7087, 7713, 7438, 7231, 7443, 7393, 7467, 7748, 7991, 7590, 7148, 7727, 7699, 7542, 7862, 7729, 7539, 7666, 7144, 7113, 7972, 7874, 7768, 7715, 7783, 7739, 7265, 7520, 7275, 7656, 7637, 7924, 7039, 7143, 7243, 7244, 7104, 7192, 7381, 7947, 7799, 7114, 7319, 7277, 7197, 7579, 7489, 7984, 7585, 7076, 7450, 7299, 7522, 7456, 7710, 7392, 7855, 7015, 7638, 7317, 7356, 7468, 7397, 7735, 7649, 7893, 7465, 7776, 7382, 7338, 7562, 7455, 7876, 7721, 7367, 7967, 7989, 7469, 7102, 7123, 7697, 7672, 7094, 7008, 7518, 7752, 7977, 7186, 7307, 7276, 7537, 7859, 7323, 7696, 7282, 7257, 7561, 7513, 7766, 7971, 7295, 7610, 7279, 7915, 7236, 7200, 7228, 7149, 7828, 7832, 7181, 7448, 7512, 7024, 7929, 7214, 7952, 7135, 7660, 7396, 7078, 7156, 7578, 7118, 7309, 7621, 7246, 7912]\n",
            "8000\n",
            "[[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " ...\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]]\n",
            "[[1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]]\n",
            "(6300, 300) (6300, 2) (1000, 300) (1000, 2) (25310, 300) (25310, 2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "# import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from math import log\n",
        "from sklearn import svm\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "\n",
        "datasets = ['20ng', 'R8', 'R52', 'ohsumed', 'mr']\n",
        "# build corpus\n",
        "dataset = dataet_name\n",
        "\n",
        "\n",
        "# Read Word Vectors\n",
        "# word_vector_file = 'data/glove.6B/glove.6B.300d.txt'\n",
        "# word_vector_file = 'data/corpus/' + dataset + '_word_vectors.txt'\n",
        "#_, embd, word_vector_map = loadWord2Vec(word_vector_file)\n",
        "# word_embeddings_dim = len(embd[0])\n",
        "\n",
        "word_embeddings_dim = 300\n",
        "word_vector_map = {}\n",
        "\n",
        "# shulffing\n",
        "doc_name_list = []\n",
        "doc_train_list = []\n",
        "doc_test_list = []\n",
        "\n",
        "with open('/content/data/' + dataset + '.txt', 'r',errors='replace') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        doc_name_list.append(line.strip())\n",
        "        temp = line.split(\"\\t\")\n",
        "        if temp[1].find('test') != -1:\n",
        "            doc_test_list.append(line.strip())\n",
        "        elif temp[1].find('train') != -1:\n",
        "            doc_train_list.append(line.strip())\n",
        "# print(doc_train_list)\n",
        "# print(doc_test_list)\n",
        "\n",
        "doc_content_list = []\n",
        "with open('/content/data/corpus/' + dataset + '.txt','r',errors='replace') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        doc_content_list.append(line.strip())\n",
        "# print(doc_content_list)\n",
        "\n",
        "train_ids = []\n",
        "for train_name in doc_train_list:\n",
        "    train_id = doc_name_list.index(train_name)\n",
        "    train_ids.append(train_id)\n",
        "# print(train_ids)\n",
        "random.shuffle(train_ids)\n",
        "\n",
        "# partial labeled data\n",
        "#train_ids = train_ids[:int(0.2 * len(train_ids))]\n",
        "\n",
        "train_ids_str = '\\n'.join(str(index) for index in train_ids)\n",
        "with open('/content/data/' + dataset + '.train.index', 'w') as f:\n",
        "    f.write(train_ids_str)\n",
        "\n",
        "\n",
        "test_ids = []\n",
        "for test_name in doc_test_list:\n",
        "    test_id = doc_name_list.index(test_name)\n",
        "    test_ids.append(test_id)\n",
        "print(test_ids)\n",
        "random.shuffle(test_ids)\n",
        "\n",
        "test_ids_str = '\\n'.join(str(index) for index in test_ids)\n",
        "with open('/content/data/' + dataset + '.test.index', 'w') as f:\n",
        "    f.write(test_ids_str)\n",
        "\n",
        "\n",
        "ids = train_ids + test_ids\n",
        "print(ids)\n",
        "print(len(ids))\n",
        "\n",
        "shuffle_doc_name_list = []\n",
        "shuffle_doc_words_list = []\n",
        "for id in ids:\n",
        "    # print(id)\n",
        "    shuffle_doc_name_list.append(doc_name_list[int(id)])\n",
        "    shuffle_doc_words_list.append(doc_content_list[int(id)])\n",
        "shuffle_doc_name_str = '\\n'.join(shuffle_doc_name_list)\n",
        "shuffle_doc_words_str = '\\n'.join(shuffle_doc_words_list)\n",
        "\n",
        "with open('/content/data/' + dataset + '_shuffle.txt', 'w') as f:\n",
        "    f.write(shuffle_doc_name_str)\n",
        "\n",
        "with open('/content/data/corpus/' + dataset + '_shuffle.txt', 'w') as f:\n",
        "    f.write(shuffle_doc_words_str)\n",
        "\n",
        "\n",
        "# build vocab\n",
        "word_freq = {}\n",
        "word_set = set()\n",
        "for doc_words in shuffle_doc_words_list:\n",
        "    words = doc_words.split()\n",
        "    for word in words:\n",
        "        word_set.add(word)\n",
        "        if word in word_freq:\n",
        "            word_freq[word] += 1\n",
        "        else:\n",
        "            word_freq[word] = 1\n",
        "\n",
        "vocab = list(word_set)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_doc_list = {}\n",
        "\n",
        "for i in range(len(shuffle_doc_words_list)):\n",
        "    doc_words = shuffle_doc_words_list[i]\n",
        "    words = doc_words.split()\n",
        "    appeared = set()\n",
        "    for word in words:\n",
        "        if word in appeared:\n",
        "            continue\n",
        "        if word in word_doc_list:\n",
        "            doc_list = word_doc_list[word]\n",
        "            doc_list.append(i)\n",
        "            word_doc_list[word] = doc_list\n",
        "        else:\n",
        "            word_doc_list[word] = [i]\n",
        "        appeared.add(word)\n",
        "\n",
        "word_doc_freq = {}\n",
        "for word, doc_list in word_doc_list.items():\n",
        "    word_doc_freq[word] = len(doc_list)\n",
        "\n",
        "word_id_map = {}\n",
        "for i in range(vocab_size):\n",
        "    word_id_map[vocab[i]] = i\n",
        "\n",
        "vocab_str = '\\n'.join(vocab)\n",
        "\n",
        "with open('/content/data/corpus/' + dataset + '_vocab.txt', 'w') as f:\n",
        "    f.write(vocab_str)\n",
        "\n",
        "label_set = set()\n",
        "for doc_meta in shuffle_doc_name_list:\n",
        "    temp = doc_meta.split('\\t')\n",
        "    label_set.add(temp[2])\n",
        "label_list = list(label_set)\n",
        "\n",
        "label_list_str = '\\n'.join(label_list)\n",
        "with open('/content/data/corpus/' + dataset + '_labels.txt', 'w') as f:\n",
        "    f.write(label_list_str)\n",
        "\n",
        "\n",
        "# x: feature vectors of training docs, no initial features\n",
        "# slect 90% training set\n",
        "train_size = len(train_ids)\n",
        "val_size = int(0.1 * train_size)\n",
        "real_train_size = train_size - val_size  # - int(0.5 * train_size)\n",
        "# different training rates\n",
        "\n",
        "real_train_doc_names = shuffle_doc_name_list[:real_train_size]\n",
        "real_train_doc_names_str = '\\n'.join(real_train_doc_names)\n",
        "\n",
        "with open('/content/data/' + dataset + '.real_train.name', 'w') as f:\n",
        "    f.write(real_train_doc_names_str)\n",
        "\n",
        "\n",
        "row_x = []\n",
        "col_x = []\n",
        "data_x = []\n",
        "for i in range(real_train_size):\n",
        "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
        "    doc_words = shuffle_doc_words_list[i]\n",
        "    words = doc_words.split()\n",
        "    doc_len = len(words)\n",
        "    for word in words:\n",
        "        if word in word_vector_map:\n",
        "            word_vector = word_vector_map[word]\n",
        "            # print(doc_vec)\n",
        "            # print(np.array(word_vector))\n",
        "            doc_vec = doc_vec + np.array(word_vector)\n",
        "\n",
        "    for j in range(word_embeddings_dim):\n",
        "        row_x.append(i)\n",
        "        col_x.append(j)\n",
        "        # np.random.uniform(-0.25, 0.25)\n",
        "        data_x.append(doc_vec[j] / doc_len)  # doc_vec[j]/ doc_len\n",
        "\n",
        "# x = sp.csr_matrix((real_train_size, word_embeddings_dim), dtype=np.float32)\n",
        "x = sp.csr_matrix((data_x, (row_x, col_x)), shape=(\n",
        "    real_train_size, word_embeddings_dim))\n",
        "\n",
        "y = []\n",
        "for i in range(real_train_size):\n",
        "    doc_meta = shuffle_doc_name_list[i]\n",
        "    temp = doc_meta.split('\\t')\n",
        "    label = temp[2]\n",
        "    one_hot = [0 for l in range(len(label_list))]\n",
        "    label_index = label_list.index(label)\n",
        "    one_hot[label_index] = 1\n",
        "    y.append(one_hot)\n",
        "y = np.array(y)\n",
        "print(y)\n",
        "\n",
        "# tx: feature vectors of test docs, no initial features\n",
        "test_size = len(test_ids)\n",
        "\n",
        "row_tx = []\n",
        "col_tx = []\n",
        "data_tx = []\n",
        "for i in range(test_size):\n",
        "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
        "    doc_words = shuffle_doc_words_list[i + train_size]\n",
        "    words = doc_words.split()\n",
        "    doc_len = len(words)\n",
        "    for word in words:\n",
        "        if word in word_vector_map:\n",
        "            word_vector = word_vector_map[word]\n",
        "            doc_vec = doc_vec + np.array(word_vector)\n",
        "\n",
        "    for j in range(word_embeddings_dim):\n",
        "        row_tx.append(i)\n",
        "        col_tx.append(j)\n",
        "        # np.random.uniform(-0.25, 0.25)\n",
        "        data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len\n",
        "\n",
        "# tx = sp.csr_matrix((test_size, word_embeddings_dim), dtype=np.float32)\n",
        "tx = sp.csr_matrix((data_tx, (row_tx, col_tx)),\n",
        "                   shape=(test_size, word_embeddings_dim))\n",
        "\n",
        "ty = []\n",
        "for i in range(test_size):\n",
        "    doc_meta = shuffle_doc_name_list[i + train_size]\n",
        "    temp = doc_meta.split('\\t')\n",
        "    label = temp[2]\n",
        "    one_hot = [0 for l in range(len(label_list))]\n",
        "    label_index = label_list.index(label)\n",
        "    one_hot[label_index] = 1\n",
        "    ty.append(one_hot)\n",
        "ty = np.array(ty)\n",
        "print(ty)\n",
        "\n",
        "# allx: the the feature vectors of both labeled and unlabeled training instances\n",
        "# (a superset of x)\n",
        "# unlabeled training instances -> words\n",
        "\n",
        "word_vectors = np.random.uniform(-0.01, 0.01,\n",
        "                                 (vocab_size, word_embeddings_dim))\n",
        "\n",
        "for i in range(len(vocab)):\n",
        "    word = vocab[i]\n",
        "    if word in word_vector_map:\n",
        "        vector = word_vector_map[word]\n",
        "        word_vectors[i] = vector\n",
        "\n",
        "row_allx = []\n",
        "col_allx = []\n",
        "data_allx = []\n",
        "\n",
        "for i in range(train_size):\n",
        "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
        "    doc_words = shuffle_doc_words_list[i]\n",
        "    words = doc_words.split()\n",
        "    doc_len = len(words)\n",
        "    for word in words:\n",
        "        if word in word_vector_map:\n",
        "            word_vector = word_vector_map[word]\n",
        "            doc_vec = doc_vec + np.array(word_vector)\n",
        "\n",
        "    for j in range(word_embeddings_dim):\n",
        "        row_allx.append(int(i))\n",
        "        col_allx.append(j)\n",
        "        # np.random.uniform(-0.25, 0.25)\n",
        "        data_allx.append(doc_vec[j] / doc_len)  # doc_vec[j]/doc_len\n",
        "for i in range(vocab_size):\n",
        "    for j in range(word_embeddings_dim):\n",
        "        row_allx.append(int(i + train_size))\n",
        "        col_allx.append(j)\n",
        "        data_allx.append(word_vectors.item((i, j)))\n",
        "\n",
        "\n",
        "row_allx = np.array(row_allx)\n",
        "col_allx = np.array(col_allx)\n",
        "data_allx = np.array(data_allx)\n",
        "\n",
        "allx = sp.csr_matrix(\n",
        "    (data_allx, (row_allx, col_allx)), shape=(train_size + vocab_size, word_embeddings_dim))\n",
        "\n",
        "ally = []\n",
        "for i in range(train_size):\n",
        "    doc_meta = shuffle_doc_name_list[i]\n",
        "    temp = doc_meta.split('\\t')\n",
        "    label = temp[2]\n",
        "    one_hot = [0 for l in range(len(label_list))]\n",
        "    label_index = label_list.index(label)\n",
        "    one_hot[label_index] = 1\n",
        "    ally.append(one_hot)\n",
        "\n",
        "for i in range(vocab_size):\n",
        "    one_hot = [0 for l in range(len(label_list))]\n",
        "    ally.append(one_hot)\n",
        "\n",
        "ally = np.array(ally)\n",
        "\n",
        "print(x.shape, y.shape, tx.shape, ty.shape, allx.shape, ally.shape)\n",
        "\n",
        "'''\n",
        "Doc word heterogeneous graph\n",
        "'''\n",
        "\n",
        "# word co-occurence with context windows\n",
        "window_size = 20\n",
        "windows = []\n",
        "\n",
        "for doc_words in shuffle_doc_words_list:\n",
        "    words = doc_words.split()\n",
        "    length = len(words)\n",
        "    if length <= window_size:\n",
        "        windows.append(words)\n",
        "    else:\n",
        "        # print(length, length - window_size + 1)\n",
        "        for j in range(length - window_size + 1):\n",
        "            window = words[j: j + window_size]\n",
        "            windows.append(window)\n",
        "            # print(window)\n",
        "\n",
        "\n",
        "word_window_freq = {}\n",
        "for window in windows:\n",
        "    appeared = set()\n",
        "    for i in range(len(window)):\n",
        "        if window[i] in appeared:\n",
        "            continue\n",
        "        if window[i] in word_window_freq:\n",
        "            word_window_freq[window[i]] += 1\n",
        "        else:\n",
        "            word_window_freq[window[i]] = 1\n",
        "        appeared.add(window[i])\n",
        "\n",
        "word_pair_count = {}\n",
        "for window in windows:\n",
        "    for i in range(1, len(window)):\n",
        "        for j in range(0, i):\n",
        "            word_i = window[i]\n",
        "            word_i_id = word_id_map[word_i]\n",
        "            word_j = window[j]\n",
        "            word_j_id = word_id_map[word_j]\n",
        "            if word_i_id == word_j_id:\n",
        "                continue\n",
        "            word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n",
        "            if word_pair_str in word_pair_count:\n",
        "                word_pair_count[word_pair_str] += 1\n",
        "            else:\n",
        "                word_pair_count[word_pair_str] = 1\n",
        "            # two orders\n",
        "            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n",
        "            if word_pair_str in word_pair_count:\n",
        "                word_pair_count[word_pair_str] += 1\n",
        "            else:\n",
        "                word_pair_count[word_pair_str] = 1\n",
        "\n",
        "row = []\n",
        "col = []\n",
        "weight = []\n",
        "\n",
        "# pmi as weights\n",
        "\n",
        "num_window = len(windows)\n",
        "\n",
        "for key in word_pair_count:\n",
        "    temp = key.split(',')\n",
        "    i = int(temp[0])\n",
        "    j = int(temp[1])\n",
        "    count = word_pair_count[key]\n",
        "    word_freq_i = word_window_freq[vocab[i]]\n",
        "    word_freq_j = word_window_freq[vocab[j]]\n",
        "    pmi = log((1.0 * count / num_window) /\n",
        "              (1.0 * word_freq_i * word_freq_j/(num_window * num_window)))\n",
        "    if pmi <= 0:\n",
        "        continue\n",
        "    row.append(train_size + i)\n",
        "    col.append(train_size + j)\n",
        "    weight.append(pmi)\n",
        "\n",
        "# word vector cosine similarity as weights\n",
        "\n",
        "'''\n",
        "for i in range(vocab_size):\n",
        "    for j in range(vocab_size):\n",
        "        if vocab[i] in word_vector_map and vocab[j] in word_vector_map:\n",
        "            vector_i = np.array(word_vector_map[vocab[i]])\n",
        "            vector_j = np.array(word_vector_map[vocab[j]])\n",
        "            similarity = 1.0 - cosine(vector_i, vector_j)\n",
        "            if similarity > 0.9:\n",
        "                print(vocab[i], vocab[j], similarity)\n",
        "                row.append(train_size + i)\n",
        "                col.append(train_size + j)\n",
        "                weight.append(similarity)\n",
        "'''\n",
        "# doc word frequency\n",
        "doc_word_freq = {}\n",
        "\n",
        "for doc_id in range(len(shuffle_doc_words_list)):\n",
        "    doc_words = shuffle_doc_words_list[doc_id]\n",
        "    words = doc_words.split()\n",
        "    for word in words:\n",
        "        word_id = word_id_map[word]\n",
        "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
        "        if doc_word_str in doc_word_freq:\n",
        "            doc_word_freq[doc_word_str] += 1\n",
        "        else:\n",
        "            doc_word_freq[doc_word_str] = 1\n",
        "\n",
        "for i in range(len(shuffle_doc_words_list)):\n",
        "    doc_words = shuffle_doc_words_list[i]\n",
        "    words = doc_words.split()\n",
        "    doc_word_set = set()\n",
        "    for word in words:\n",
        "        if word in doc_word_set:\n",
        "            continue\n",
        "        j = word_id_map[word]\n",
        "        key = str(i) + ',' + str(j)\n",
        "        freq = doc_word_freq[key]\n",
        "        if i < train_size:\n",
        "            row.append(i)\n",
        "        else:\n",
        "            row.append(i + vocab_size)\n",
        "        col.append(train_size + j)\n",
        "        idf = log(1.0 * len(shuffle_doc_words_list) /\n",
        "                  word_doc_freq[vocab[j]])\n",
        "        weight.append(freq * idf)\n",
        "        doc_word_set.add(word)\n",
        "\n",
        "node_size = train_size + vocab_size + test_size\n",
        "adj = sp.csr_matrix(\n",
        "    (weight, (row, col)), shape=(node_size, node_size))\n",
        "\n",
        "# dump objects\n",
        "with open(\"/content/data/ind.{}.x\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(x, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.y\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(y, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.tx\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(tx, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.ty\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(ty, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.allx\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(allx, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.ally\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(ally, f)\n",
        "\n",
        "with open(\"/content/data/ind.{}.adj\".format(dataset), 'wb') as f:\n",
        "    pkl.dump(adj, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kI5wBoAQVUqy"
      },
      "outputs": [],
      "source": [
        "word_vector_map = {}\n",
        "\n",
        "# shulffing\n",
        "doc_name_list = []\n",
        "doc_train_list = []\n",
        "doc_test_list = []\n",
        "\n",
        "with open('/content/data/' + dataset + '.txt', 'r',errors='replace') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        doc_name_list.append(line.strip())\n",
        "        temp = line.split(\"\\t\")\n",
        "        if temp[1].find('test') != -1:\n",
        "            doc_test_list.append(line.strip())\n",
        "        elif temp[1].find('train') != -1:\n",
        "            doc_train_list.append(line.strip())\n",
        "# print(doc_train_list)\n",
        "# print(doc_test_list)\n",
        "\n",
        "doc_content_list = []\n",
        "with open('/content/data/corpus/' + dataset + '.txt','r',errors='replace') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        doc_content_list.append(line.strip())\n",
        "# print(doc_content_list)\n",
        "\n",
        "train_ids = []\n",
        "for train_name in doc_train_list:\n",
        "    train_id = doc_name_list.index(train_name)\n",
        "    train_ids.append(train_id)\n",
        "# print(train_ids)\n",
        "# random.shuffle(train_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuY6Va1TmOTd"
      },
      "source": [
        "### delete to freeram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lMQrMwqXmQYk"
      },
      "outputs": [],
      "source": [
        "# del(doc_name_list)\n",
        "# del(doc_train_list)\n",
        "# del(doc_test_list)\n",
        "# del(lines)\n",
        "# del(train_ids)\n",
        "# del(train_ids_str)\n",
        "# del(test_ids)\n",
        "# del(test_ids_str)\n",
        "# del(ids)\n",
        "# del(shuffle_doc_name_list)\n",
        "# del(shuffle_doc_words_list)\n",
        "# del(word_doc_list)\n",
        "# del(word_id_map)\n",
        "# del(vocab_str)\n",
        "# del(label_set)\n",
        "# del(train_size)\n",
        "# del(real_train_doc_names)\n",
        "# del(real_train_doc_names_str)\n",
        "# del(row_x)\n",
        "# del(col_x)\n",
        "# del(data_x)\n",
        "# del(x)\n",
        "# del(y)\n",
        "# del(row_tx)\n",
        "# del(col_tx)\n",
        "# del(data_tx)\n",
        "# del(tx)\n",
        "# del(ty)\n",
        "# del(word_vectors)\n",
        "# del(row_allx)\n",
        "# del(col_allx)\n",
        "# del(data_allx)\n",
        "# del(row_allx)\n",
        "# del(col_allx)\n",
        "# del(data_allx)\n",
        "# del(allx)\n",
        "# del(ally)\n",
        "# del(windows)\n",
        "# del(word_window_freq)\n",
        "# del(word_pair_count)\n",
        "# del(row)\n",
        "# del(col)\n",
        "# del(weight)\n",
        "# del(num_window)\n",
        "# del(doc_word_freq)\n",
        "# del()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAmJ-_ndwFag"
      },
      "source": [
        "## training data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s93YEqi8vLSZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "# from utils import load_corpus,normalize_adj\n",
        "from scipy.sparse import eye\n",
        "import torch\n",
        "import dgl\n",
        "def encode_input(text, tokenizer):\n",
        "    input = tokenizer(text, max_length=256, truncation=True, padding='max_length', return_tensors='pt')\n",
        "#     print(input.keys())\n",
        "    return input.input_ids, input.attention_mask\n",
        "class Data_set(Dataset):\n",
        "    def __init__(self,name):\n",
        "        adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(name)\n",
        "        doc_mask=train_mask+test_mask+val_mask\n",
        "        adj=normalize_adj(adj+eye(adj.shape[0]))\n",
        "        train_num=train_mask.sum().item()\n",
        "        val_num=val_mask.sum().item()\n",
        "        test_num=test_mask.sum().item()\n",
        "        node_size=adj.shape[0]\n",
        "        y=torch.tensor(y_train+y_val+y_test)\n",
        "        self.y=torch.argmax(y,-1)\n",
        "\n",
        "        self.train_index=[i for i in range(train_num+val_num)] + [i for i in range(node_size-test_num,node_size)]\n",
        "        corpse_file = open('/content/data/corpus/' + name +'_shuffle.txt').readlines()\n",
        "        token=AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
        "        # token=AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        self.dataset,self.attention_mask=encode_input(corpse_file,token)\n",
        "        self.attention_mask=torch.tensor(self.attention_mask)\n",
        "        self.dataset=torch.tensor(self.dataset)\n",
        "        self.graph=dgl.from_scipy(adj,eweight_name='w')\n",
        "        self.graph.ndata['label']=self.y\n",
        "        self.label_num=len(y_train[0])\n",
        "        self.graph.edata['w']=self.graph.edata['w'].float()\n",
        "        self.graph.ndata['train_mask']=torch.tensor(train_mask)\n",
        "        self.graph.ndata['valid_mask']=torch.tensor(val_mask)\n",
        "        self.graph.ndata['test_mask']=torch.tensor(test_mask)\n",
        "        self.train_mask=train_mask\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    def __getitem__(self, item):\n",
        "        return self.dataset[item],self.y[self.train_index[item]],self.attention_mask[item],self.train_mask[self.train_index[item]],self.train_index[item]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlbcFsY4y7Vb"
      },
      "source": [
        "## pretrain(fine tune) data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DOKNKP_TzBid"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch import tensor\n",
        "import pickle\n",
        "\n",
        "\n",
        "class DataSet(Dataset):\n",
        "    def __init__(self, name, usage, label_dict=None):\n",
        "        tokenizers = AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
        "        # tokenizers = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        # data=open(usage+'_data.txt').readlines()\n",
        "        # label=open(usage+'_label.txt').readlines()\n",
        "        # self.data=[tokenizers.encode(each,max_length=512) for each in data]\n",
        "        # self.label=[int(i) for i in label]\n",
        "        # self.class_num=23\n",
        "        label_path = '/content/data/' + name + '_labels.pkl'\n",
        "        indexs = '/content/data/' + name + '_indexs.pkl'\n",
        "        current_usage = '/content/data/' + name + '_' + usage + '_index.pkl'\n",
        "        current_usage = pickle.load(open(current_usage, 'rb'))\n",
        "        orig_data_path = '/content/data/corpus/' + name + '.txt'\n",
        "        orig_data = open(orig_data_path).readlines()\n",
        "        indexs = pickle.load(open(indexs, 'rb'))\n",
        "        labels = pickle.load(open(label_path, 'rb'))\n",
        "        orig_data = [orig_data[i] for i in indexs]\n",
        "        orig_data = [tensor(tokenizers.encode(each, max_length=256,truncation=True)) for each in orig_data]\n",
        "        self.data = [orig_data[i] for i in current_usage]\n",
        "        self.label = [labels[i] for i in current_usage]\n",
        "        self.class_num = len(pickle.load(open('/content/data/' + name + '_label_dict.pkl', 'rb')))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return tensor(self.data[item]), tensor(self.label[item])\n",
        "# data=DataSet('ohsumed','train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IepFinMmzJXb"
      },
      "source": [
        "## remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjw-nCvYzK21",
        "outputId": "d69c3d1f-b775-422f-ce86-cd0c699c566d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'have', 'her', 'hadn', \"that'll\", 'wouldn', 'some', 'on', 'a', 'is', 'over', 'ourselves', 'than', 'your', 'our', \"you're\", 'will', 'each', 'again', 'did', \"shan't\", \"she's\", \"wasn't\", 'do', 'or', 'you', 'their', 'such', 'which', 'because', \"don't\", 'its', 'nor', 'shouldn', 'his', 'out', 'being', \"you'd\", \"won't\", 'all', 'if', 'between', 'shan', 'few', 'am', 'the', 'these', \"wouldn't\", 'mustn', 'didn', 'that', \"you'll\", 'very', 'what', 'most', 'hasn', 'ours', 'them', 'once', 'own', 'couldn', \"hasn't\", 'hers', 'wasn', 'ma', 'o', 'haven', 'theirs', 'up', 'then', 'doing', 'during', 'in', 'can', 'after', 'where', 'does', 'to', 'themselves', 'an', \"haven't\", 'with', 'no', 'they', 'i', 'who', 'were', 'itself', 'both', \"mustn't\", \"needn't\", 'when', \"weren't\", 'ain', 'isn', 'here', 'aren', 'from', \"couldn't\", 'm', \"shouldn't\", 'd', \"it's\", 'yourselves', \"didn't\", 'whom', 'he', 'into', 'll', 'him', 're', \"mightn't\", 'of', 'under', 'only', 'so', 'those', \"isn't\", 'too', 'myself', 'below', 'same', 'herself', 'won', 'other', 'until', 'needn', 'it', 'my', 'was', 'been', 'are', 'by', 'for', 'off', 'down', 'as', 'having', 'now', 'about', 'she', 'how', \"doesn't\", \"you've\", \"hadn't\", 'at', 'doesn', 'has', 'any', 'y', 'but', 'while', 'this', 't', 's', 'mightn', 'weren', 'we', 'against', 'yourself', 'and', 'yours', 'just', 'me', 'more', 've', \"aren't\", 'be', 'not', 'there', 'himself', 'through', 'further', \"should've\", 'should', 'don', 'above', 'had', 'before', 'why'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:00<00:00, 687506.29it/s]\n",
            "100%|██████████| 8000/8000 [00:00<00:00, 85196.83it/s]\n",
            "100%|██████████| 8000/8000 [00:00<00:00, 63286.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min_len : 0\n",
            "Max_len : 325\n",
            "Average_len : 28.0705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "# from utils import clean_str\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "dataset = dataet_name\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)\n",
        "\n",
        "# Read Word Vectors\n",
        "# word_vector_file = 'data/glove.6B/glove.6B.200d.txt'\n",
        "# vocab, embd, word_vector_map = loadWord2Vec(word_vector_file)\n",
        "# word_embeddings_dim = len(embd[0])\n",
        "# dataset = '20ng'\n",
        "\n",
        "doc_content_list = []\n",
        "# with open('data/wiki_long_abstracts_en_text.txt', 'r') as f:\n",
        "with open('/content/data/corpus/' + dataset + '.txt', 'rb') as f:\n",
        "    for line in tqdm(f.readlines()):\n",
        "        doc_content_list.append(line.strip().decode('latin1'))\n",
        "\n",
        "word_freq = {}  # to remove rare words\n",
        "\n",
        "for doc_content in tqdm(doc_content_list):\n",
        "    temp = clean_str(doc_content)\n",
        "    words = temp.split()\n",
        "    for word in words:\n",
        "        if word in word_freq:\n",
        "            word_freq[word] += 1\n",
        "        else:\n",
        "            word_freq[word] = 1\n",
        "\n",
        "clean_docs = []\n",
        "for doc_content in tqdm(doc_content_list):\n",
        "    temp = clean_str(doc_content)\n",
        "    words = temp.split()\n",
        "    doc_words = []\n",
        "    for word in words:\n",
        "        # word not in stop_words and word_freq[word] >= 5\n",
        "        if dataset == 'mr':\n",
        "            doc_words.append(word)\n",
        "        elif word not in stop_words and word_freq[word] >= 5:\n",
        "            doc_words.append(word)\n",
        "\n",
        "    doc_str = ' '.join(doc_words).strip()\n",
        "    # if doc_str == '':\n",
        "    # doc_str = temp\n",
        "    clean_docs.append(doc_str)\n",
        "\n",
        "clean_corpus_str = '\\n'.join(clean_docs)\n",
        "\n",
        "with open('/content/data/corpus/' + dataset + '.clean.txt', 'w') as f:\n",
        "    f.write(clean_corpus_str)\n",
        "\n",
        "# dataset = '20ng'\n",
        "min_len = 10000\n",
        "aver_len = 0\n",
        "max_len = 0\n",
        "\n",
        "with open('/content/data/corpus/' + dataset + '.clean.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        temp = line.split()\n",
        "        aver_len = aver_len + len(temp)\n",
        "        if len(temp) < min_len:\n",
        "            min_len = len(temp)\n",
        "        if len(temp) > max_len:\n",
        "            max_len = len(temp)\n",
        "\n",
        "aver_len = 1.0 * aver_len / len(lines)\n",
        "print('Min_len : ' + str(min_len))\n",
        "print('Max_len : ' + str(max_len))\n",
        "print('Average_len : ' + str(aver_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9x8LC2ow58s",
        "outputId": "2d3bbba0-10ee-4bd1-a086-9aeb049a2210"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6241/6241 [00:00<00:00, 803408.36it/s]\n",
            "100%|██████████| 6241/6241 [00:00<00:00, 48246.20it/s]\n"
          ]
        }
      ],
      "source": [
        "doc_content_list = []\n",
        "dataset = 'VSMEC'\n",
        "# with open('data/wiki_long_abstracts_en_text.txt', 'r') as f:\n",
        "with open('/content/data/corpus/' + dataset + '.txt', 'rb') as f:\n",
        "    for line in tqdm(f.readlines()):\n",
        "        doc_content_list.append(line.strip().decode('utf-8'))\n",
        "\n",
        "word_freq = {}  # to remove rare words\n",
        "c = []\n",
        "for doc_content in tqdm(doc_content_list):\n",
        "    temp = clean_str(doc_content)\n",
        "    words = temp.split()\n",
        "    c.append(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMsmyNb4zFAs",
        "outputId": "86deb89b-2ebf-479c-ad41-2a14f34f1698"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cho', 'mình', 'xin', 'bài', 'nhạc', 'tên', 'là', 'gì', 'với', 'ạ', 'khác']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A2Vtjt2izCFl",
        "outputId": "94a4c3af-c27a-41fe-8416-38209ea3d34c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cho mình xin bài nhạc tên là gì với ạ khác'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_content_list[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJam6vuZz3rr"
      },
      "source": [
        "## tokenize sentence "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMv8NlB_zLGH",
        "outputId": "5f11b731-4a9c-4131-a623-fb35a527ed9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8000/8000 [00:00<00:00, 18009.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating word relations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 108283/108283 [00:35<00:00, 3040.60it/s]\n"
          ]
        }
      ],
      "source": [
        "def convert_data_to_index(context):\n",
        "    dictionary = {}\n",
        "    index_context = []\n",
        "    context_length = len(context)\n",
        "    for line in context:\n",
        "        line = line.strip().lower().split(' ')\n",
        "        for word in line:\n",
        "            if word not in dictionary.keys():\n",
        "                dictionary[word] = len(dictionary.keys()) + context_length\n",
        "        index_context.append([dictionary[each] for each in line])\n",
        "    return dictionary, index_context\n",
        "\n",
        "\n",
        "def word_window_num(windows):\n",
        "    single_word_fluency = collections.defaultdict(int)\n",
        "    tuple_word_fluency = collections.defaultdict(int)\n",
        "    for window in tqdm(windows):\n",
        "        current_appear = set()\n",
        "        for i in range(len(window)):\n",
        "            if window[i] not in current_appear:\n",
        "                single_word_fluency[window[i]] += 1\n",
        "                current_appear.add(window[i])\n",
        "            for j in range(i + 1, len(window)):\n",
        "                str1=str(window[i])+','+str(window[j])\n",
        "                str2=str(window[j])+','+str(window[i])\n",
        "                if window[i] == window[j]:\n",
        "                    continue\n",
        "                if str1 in current_appear or str2 in current_appear:\n",
        "                    continue\n",
        "                else:\n",
        "                    tuple_word_fluency[str1] += 1\n",
        "                    tuple_word_fluency[str2] += 1\n",
        "                    current_appear.add(str1)\n",
        "                    current_appear.add(str2)\n",
        "    return single_word_fluency, tuple_word_fluency\n",
        "\n",
        "\n",
        "def word_document(indexed_document, start, end, weight):\n",
        "    word_document = collections.defaultdict(int)\n",
        "    for document in indexed_document:\n",
        "        appear = set()\n",
        "        for word in document:\n",
        "            if word not in appear:\n",
        "                word_document[word] += 1\n",
        "                appear.add(word)\n",
        "    for i in range(len(indexed_document)):\n",
        "        word_dict = collections.defaultdict(int)\n",
        "        line = indexed_document[i]\n",
        "        for word in line:\n",
        "            word_dict[word] += 1\n",
        "        for key in word_dict.keys():\n",
        "            start.append(i)\n",
        "            end.append(key)\n",
        "            TF = word_dict[key] / len(indexed_document[i])\n",
        "            IDF = math.log(len(indexed_document) / word_document[key])\n",
        "            weight.append(TF * IDF)\n",
        "            start.append(key)\n",
        "            end.append(i)\n",
        "            weight.append(TF*IDF)\n",
        "\n",
        "    return start, end, weight\n",
        "\n",
        "\n",
        "def build_graph(index_context: list, window_size):\n",
        "    windows = []\n",
        "    for line in tqdm(index_context):\n",
        "        if len(line) <= window_size:\n",
        "            windows.append(line)\n",
        "        else:\n",
        "            for i in range(len(line) - window_size + 1):\n",
        "                windows.append(line[i:i + window_size])\n",
        "    print('generating word relations')\n",
        "    single_word_fluency, tuple_word_fluency = word_window_num(windows)\n",
        "    window_num = len(windows)\n",
        "    start = []\n",
        "    end = []\n",
        "    weight = []\n",
        "    for sen in tuple_word_fluency.keys():\n",
        "        s,t=sen.split(',')\n",
        "        s,t=int(s),int(t)\n",
        "        score = math.log(tuple_word_fluency[str(s)+','+str(t)] / window_num / (\n",
        "                single_word_fluency[s] / window_num * single_word_fluency[t] / window_num))\n",
        "        if score < 0:\n",
        "            continue\n",
        "        start.append(s)\n",
        "        end.append(t)\n",
        "        weight.append(score)\n",
        "    start, end, weight = word_document(index_context, start, end, weight)\n",
        "    return start, end, weight\n",
        "\n",
        "dataset = dataet_name\n",
        "file_path = '/content/data/' + dataset + '.txt'\n",
        "with open(file_path) as f:\n",
        "    lines = f.readlines()\n",
        "titles = lines\n",
        "orig_titles = copy.deepcopy(titles)\n",
        "content_path = '/content/data/corpus/' + dataset + '.clean.txt'\n",
        "content = open(content_path).readlines()\n",
        "shuffle(titles)\n",
        "indexs = [orig_titles.index(each) for each in titles]\n",
        "content=[content[i] for i in indexs]\n",
        "dictonary, index_data = convert_data_to_index(content)\n",
        "train_index = []\n",
        "test_index = []\n",
        "label_dict = {}\n",
        "labels = []\n",
        "for i in range(len(indexs)):\n",
        "    line = titles[i].strip().split()\n",
        "    if line[1] == 'train':\n",
        "        train_index.append(i)\n",
        "    else:\n",
        "        test_index.append(i)\n",
        "    label = line[-1]\n",
        "    if label not in label_dict.keys():\n",
        "        label_dict[label] = len(label_dict)\n",
        "    labels.append(label_dict[label])\n",
        "shuffle(train_index)\n",
        "valid_index = train_index[int(len(train_index) * 0.9):]\n",
        "train_index = train_index[:int(len(train_index) * 0.9)]\n",
        "start, end, weight = build_graph(index_data, 20)\n",
        "matrix = coo_matrix((weight, (start, end)))\n",
        "\n",
        "pickle.dump(matrix, open('/content/data/' + dataset + '_matrix.pkl', 'wb'))\n",
        "pickle.dump(indexs, open('/content/data/' + dataset + '_indexs.pkl', 'wb'))\n",
        "pickle.dump(train_index, open('/content/data/' +dataset + '_train_index.pkl', 'wb'))\n",
        "pickle.dump(test_index, open('/content/data/' + dataset + '_test_index.pkl', 'wb'))\n",
        "pickle.dump(valid_index, open('/content/data/' + dataset + '_valid_index.pkl', 'wb'))\n",
        "pickle.dump(labels, open('/content/data/' + dataset + '_labels.pkl', 'wb'))\n",
        "pickle.dump(dictonary, open('/content/data/' + dataset + '_dict.pkl', 'wb'))\n",
        "pickle.dump(label_dict, open('/content/data/' +dataset + '_label_dict.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_q6Tzfw02uC"
      },
      "source": [
        "## finetune phobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "ddb198b6ff7a4081bc0bc56f0aae35ea",
            "9bd8cf9690094c0f9eda7754346cdc14",
            "2963fe54d0a844149bc3c2e129809170",
            "1f2b535b68d5427289ffb3f7b0607c1e",
            "0d58382d49784b37bf72b027087eb237",
            "11e04d1208494c6c9ca811ab2d197440",
            "cd7f74228eb640b9baa506c5b01d2859",
            "bdfc0c1f537c4a60ab0f650ab6ff30f4",
            "ed97233c6fff4025964dafb2f118504d",
            "2aa6649dade74cc7b4a3fba5b5186cf8",
            "13995d512ea94a8fa09c07fbf6e8e187",
            "18899397f90e47ceb538849974eb91bd",
            "c7ec4380c6934d80a371d4666d40c6ee",
            "27308b02666940949a37dbf4b649ed7b",
            "6bdc77a21c24463b9e9d4d00a7da4a09",
            "16586df8986d477b906af5609395d161",
            "593fcc4c53ae4384a135115f5526cade",
            "71b84c6228f2429590dfbd7b79f54ff1",
            "cd3ea33d11c347b18ac432dab92940c3",
            "a98186f1f66d4ba8949d7f27f13ebea1",
            "7367e22612fd415494d3da2264753bab",
            "68b51af379c046d28c0a8b28cc94fbf2",
            "8b340fa45b6f486e8962c4a8975bdb52",
            "d20b913337264667b3625f6126053c92",
            "468fb9f6718448aca2c34023d5d79fe2",
            "c1c9e6b8cd9b43eb8a577382d4fed4cd",
            "d09c5901bf3d433faae0006a9017c5fd",
            "2ebc3d40fbef490c80f35eb4bd172df0",
            "295b279b4a5c4231af60655391a311f2",
            "2ebdced46c384751a880207e634a1f82",
            "33bf7b3c72a54ba2a609eaec4b7a128a",
            "dfd65612714448e4928e72e08fff5637",
            "e2f9630829584f209a2317b11fb44e49"
          ]
        },
        "id": "UTxSykia035L",
        "outputId": "391b0698-cac7-4c3c-eb40-00965bd38290"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb198b6ff7a4081bc0bc56f0aae35ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18899397f90e47ceb538849974eb91bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/895k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b340fa45b6f486e8962c4a8975bdb52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "def collate_fn(batch):\n",
        "    src, label = [], []\n",
        "    for s, t in batch:\n",
        "        src.append(s)\n",
        "        label.append(t)\n",
        "    src = pad_sequence(src, batch_first=True, padding_value=0)\n",
        "    label = torch.tensor(label)\n",
        "    return src, label\n",
        "\n",
        "\n",
        "def train(i, model, optim, data_loader, device):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total=0\n",
        "    for src, trg in tqdm(data_loader):\n",
        "        optim.zero_grad()\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        predict = model(src)\n",
        "        loss = cross_entropy(predict, trg.long())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        losses.append(loss.item())\n",
        "        correct += (torch.argmax(predict, -1) == trg).sum().item()\n",
        "        total+=predict.shape[0]\n",
        "    print(\"train epoch {} accuracy {} || loss {}\".format(i, correct / total, mean(losses)))\n",
        "\n",
        "\n",
        "def eval(i, model, best_loss, no_increase, data_loader, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for src, trg in tqdm(data_loader):\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        predict = model(src)\n",
        "        loss = cross_entropy(predict, trg.long())\n",
        "        losses.append(loss.item())\n",
        "        correct += (torch.argmax(predict, -1) == trg).sum().item()\n",
        "        total += predict.shape[0]\n",
        "    loss = mean(losses)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        torch.save(model.state_dict(), 'best_pretrain_phobert.pkl')\n",
        "        no_increase = 0\n",
        "    else:\n",
        "        no_increase += 1\n",
        "    print(\"eval epoch {} accuracy {} || loss {}\".format(i, correct / total, mean(losses)))\n",
        "    return best_loss, no_increase\n",
        "\n",
        "\n",
        "def test( model, data_loader, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for src, trg in tqdm(data_loader):\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        predict = model(src)\n",
        "        loss = cross_entropy(predict, trg.long())\n",
        "        losses.append(loss.item())\n",
        "        correct += (torch.argmax(predict, -1) == trg).sum().item()\n",
        "        total += predict.shape[0]\n",
        "    loss = mean(losses)\n",
        "    print(\"test accuracy {} || loss {}\".format( correct / total, mean(losses)))\n",
        "\n",
        "\n",
        "dataset = dataet_name\n",
        "# args = get_args()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "data = DataSet(dataset, 'train')\n",
        "train_loader = DataLoader(data, collate_fn=collate_fn, batch_size=7,shuffle=True)\n",
        "valid_data = DataSet(dataset, 'valid')\n",
        "val_loader = DataLoader(valid_data, collate_fn=collate_fn, batch_size=7)\n",
        "test_data=DataSet(dataset,'test')\n",
        "test_loader=DataLoader(test_data,collate_fn=collate_fn,batch_size=7)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qOq0M5pxHuJO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34a54de438f642c68c970793a8be86de",
            "f6b412395b3740ba88ea59691a8d5984",
            "bc17ba5aa25d48fb997a39c712386407",
            "c3687968bfed4f438edc7efa57e44c58",
            "835f0e1f336a4b1bb14f3ea33ba088b8",
            "f8fddcb11f7543e48f9fd099f4a73dbf",
            "0471d9c9aef848409945e852fe89b80d",
            "4b2356c1aa1e441ea37ed2c99a6d2285",
            "375523413d4e4a22aadbb5fa128f4ebf",
            "c866dc4d6f414db2989b3a70ed2e4cbc",
            "697a6841f3374692ae3344908cc654da"
          ]
        },
        "id": "dUaTv-YzJ044",
        "outputId": "93824344-ba5d-4ac7-c8b2-92b3f031ca98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34a54de438f642c68c970793a8be86de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 900/900 [02:31<00:00,  5.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 0 accuracy 0.9214285714285714 || loss 0.1780990522631651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 0 accuracy 0.9442857142857143 || loss 0.11331650348904077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:29<00:00,  6.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 1 accuracy 0.9577777777777777 || loss 0.09311121890981061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 1 accuracy 0.9628571428571429 || loss 0.0859376654837979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 2 accuracy 0.9663492063492064 || loss 0.07665733697125689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 2 accuracy 0.9585714285714285 || loss 0.08636046658153645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 3 accuracy 0.9763492063492063 || loss 0.056068493031392184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 3 accuracy 0.9642857142857143 || loss 0.08689971587344189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:29<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 4 accuracy 0.9855555555555555 || loss 0.035119901684617316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 4 accuracy 0.9457142857142857 || loss 0.1359344152547419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:27<00:00,  6.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 5 accuracy 0.9904761904761905 || loss 0.02347027996807204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 5 accuracy 0.9514285714285714 || loss 0.17120389128263924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 6 accuracy 0.9938095238095238 || loss 0.017921170811379044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 6 accuracy 0.9271428571428572 || loss 0.23790726555511355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 7 accuracy 0.9895238095238095 || loss 0.029809769124840388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 7 accuracy 0.9585714285714285 || loss 0.16337823301975732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 8 accuracy 0.9955555555555555 || loss 0.014767863418932797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 8 accuracy 0.9557142857142857 || loss 0.15678860538959272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 9 accuracy 0.9968253968253968 || loss 0.007546681734869102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 9 accuracy 0.9542857142857143 || loss 0.24653905410450533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [02:28<00:00,  6.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch 10 accuracy 0.996984126984127 || loss 0.011639417441458338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval epoch 10 accuracy 0.9571428571428572 || loss 0.1768391746483394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 64/900 [00:10<02:19,  6.01it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f102f441f248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mno_increasing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mno_increasing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_increasing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-908cde979482>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(i, model, optim, data_loader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    163\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    220\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model=finetunedphoBert(data.class_num)\n",
        "model = model.to(device)\n",
        "optim = AdamW(model.parameters(), lr=2e-5)\n",
        "best_loss = 1e10\n",
        "no_increasing = 0\n",
        "for i in range(12):\n",
        "    train(i, model, optim, train_loader, device)\n",
        "    with torch.no_grad():\n",
        "        no_increasing, best_loss = eval(i, model, best_loss, no_increasing, val_loader, device)\n",
        "        if no_increasing>3:\n",
        "            break\n",
        "model.load_state_dict(torch.load('best_pretrain_phobert.pkl'))\n",
        "with torch.no_grad():\n",
        "    test(model,test_loader,device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOb8_9is3XLw"
      },
      "source": [
        "# trainning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OZUmhzZQ3S2e"
      },
      "outputs": [],
      "source": [
        "setup_seed(9)\n",
        "def train(i, dataset, model: phoBertGCN, optim, features, graph, device):\n",
        "    print(' epoch ',i+1)\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    increase=0\n",
        "    for src, label, attention,mask, index in tqdm(dataset):\n",
        "        mask = mask.to(device)\n",
        "        src = src.to(device)\n",
        "        attention=attention.to(device)\n",
        "        label = label.to(device)\n",
        "        predict = model(src, features,attention, graph, index)\n",
        "        predict = predict[mask]\n",
        "        label = label[mask]\n",
        "        if predict.shape[0] == 0:\n",
        "            continue\n",
        "        # print(predict,label)\n",
        "        loss = nll_loss(torch.log(predict), label)\n",
        "        loss.backward(retain_graph=True)\n",
        "        increase+=1\n",
        "        if increase%3==0:\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            increase=0\n",
        "        total += predict.shape[0]\n",
        "        correct += (torch.argmax(predict, -1) == label).sum().item()\n",
        "        losses.append(loss.item())\n",
        "        a = torch.Tensor.cpu(torch.argmax(predict, -1))\n",
        "        b = torch.Tensor.cpu(label)\n",
        "    print(\"training set : (loss {} || accuracy {}  || f1_score {})\".format(mean(losses), correct / total,f1_score(a,b,average= f1_type)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yLCgJvzlMvWS"
      },
      "outputs": [],
      "source": [
        "def update_features(features, dataset, model, device):\n",
        "    print('update featre')\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for src, label,attention, mask, idx in tqdm(dataset):\n",
        "            src = src.to(device)\n",
        "            attention=attention.to(device)\n",
        "            current_features = model.phoBertModel.model(src,attention_mask=attention).last_hidden_state[:, 0, :]\n",
        "            features[idx] = current_features.detach()\n",
        "    return features\n",
        "def eval(i, dataset, model: phoBertGCN, features, graph, usage, device, best_loss=None, best_accuracy=None,\n",
        "         no_increasing=None):\n",
        "    model.eval()\n",
        "    if usage == 'valid':\n",
        "        mask = graph.ndata['valid_mask']\n",
        "    else:\n",
        "        mask = graph.ndata['test_mask']\n",
        "    mask = (mask == 1)\n",
        "    if usage == 'test':\n",
        "        model.load_state_dict(torch.load('best_phoBert_GCN_model.pkl'))\n",
        "        features = update_features(features, dataset, model, device)\n",
        "    predict = model.phoBertModel.linear(features)\n",
        "    graph_predict = model.gcn(graph, features)\n",
        "    predict = softmax(predict[mask], -1) * (1 - model.lam) + softmax(graph_predict[mask], -1) * model.lam\n",
        "    label = graph.ndata['label']\n",
        "    loss = nll_loss(torch.log(predict), label[mask])\n",
        "    correct = (torch.argmax(predict, -1) == label[mask]).sum().item()\n",
        "    # print(label[mask])\n",
        "    a = torch.Tensor.cpu(torch.argmax(predict, -1))\n",
        "    b = torch.Tensor.cpu(label[mask])\n",
        "    # print(torch.argmax(predict, -1)\n",
        "    total = sum(mask).item()\n",
        "    print(\"{} loss {} || accuracy {} || f1_score {}\".format(usage, loss.item(), correct / total,f1_score(a,b,average= 'macro')))\n",
        "    if usage == 'valid':\n",
        "        if best_loss > loss.item():\n",
        "            best_loss = loss.item()\n",
        "            no_increasing = 0\n",
        "            torch.save(model.state_dict(), 'best_phoBert_GCN_model.pkl')\n",
        "            print(\"saving to file best_phoBert_GCN_model.pkl\")\n",
        "\n",
        "        else:\n",
        "            no_increasing += 1\n",
        "        if best_accuracy < correct / total:\n",
        "            best_accuracy = correct / total\n",
        "            torch.save(model.state_dict(), 'best_accuracy.pkl')\n",
        "            print(\"saving to file best_accuracy.pkl\")\n",
        "        return best_loss, best_accuracy, no_increasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "9VfWhAsv3bvA",
        "outputId": "61240fd2-25d6-4f16-f5bd-f1e8bafe094f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6300, 300) (6300, 2) (1000, 300) (1000, 2) (25310, 300) (25310, 2)\n",
            "26310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update featre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [01:53<00:00, 10.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " epoch  1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [06:42<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set : (loss 0.8503361744700246 || accuracy 0.5914285714285714  || f1_score 0.37499999999999994)\n",
            "update featre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [01:52<00:00, 10.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid loss 0.7488362193107605 || accuracy 0.6371428571428571 || f1_score 0.38917975567190227\n",
            "saving to file best_phoBert_GCN_model.pkl\n",
            "saving to file best_accuracy.pkl\n",
            " epoch  2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [06:42<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set : (loss 0.5179453734976621 || accuracy 0.7801587301587302  || f1_score 0.42857142857142855)\n",
            "update featre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [01:52<00:00, 10.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid loss 0.20643958449363708 || accuracy 0.9771428571428571 || f1_score 0.9750214102198117\n",
            "saving to file best_phoBert_GCN_model.pkl\n",
            "saving to file best_accuracy.pkl\n",
            " epoch  3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [06:42<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set : (loss 0.1815943146940917 || accuracy 0.9922222222222222  || f1_score 1.0)\n",
            "update featre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [01:52<00:00, 10.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid loss 0.17127282917499542 || accuracy 0.9914285714285714 || f1_score 0.9907154415470727\n",
            "saving to file best_phoBert_GCN_model.pkl\n",
            "saving to file best_accuracy.pkl\n",
            " epoch  4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 1122/1143 [06:35<00:07,  2.84it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fb80c8c495d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a1e136392852>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(i, dataset, model, optim, features, graph, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4478a3552898>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, features, attention, graph, indexs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlast_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mgcn_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mbert_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4478a3552898>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feature)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mpredict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mpredict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mdegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'both'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                     \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "dataset = Data_set(dataet_name)\n",
        "graph = dataset.graph.to(device)\n",
        "data_loader = DataLoader(dataset,  batch_size=7, shuffle=True)\n",
        "features = torch.zeros(graph.num_nodes(), 768, requires_grad=False).to(device)\n",
        "model = phoBertGCN('./best_pretrain_phobert.pkl', dataset.label_num)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.Adam([{'params': model.gcn.parameters(), 'lr': 1e-3}, {'params': model.phoBertModel.parameters(), 'lr': 1e-5}])\n",
        "scheduler=lr_scheduler.MultiStepLR(optim,milestones=[30],gamma=0.1)\n",
        "features = update_features(features, data_loader, model, device)\n",
        "best_loss = 1e10\n",
        "no_increasing = 0\n",
        "best_accuracy = 0\n",
        "for i in range(6):\n",
        "    torch.cuda.empty_cache()\n",
        "    train(i, data_loader, model, optim, features, graph, device)\n",
        "    scheduler.step()\n",
        "    torch.cuda.empty_cache()\n",
        "    with torch.no_grad():\n",
        "        features = update_features(features, data_loader, model, device)\n",
        "        best_loss, best_accuracy, no_increasing = eval(i, data_loader, model, features, graph, 'valid', device,\n",
        "                                                        best_loss,\n",
        "                                                        best_accuracy,\n",
        "                                                        no_increasing)\n",
        "    if no_increasing >= 10:\n",
        "        break  # for i in range(20):\n",
        "with torch.no_grad():\n",
        "    eval(0, data_loader, model, features, graph, 'test', device, best_loss, best_accuracy, no_increasing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iawavg970ysc",
        "outputId": "7d831c04-b388-4261-9d0b-98ae0f2cfa1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update featre\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1143/1143 [01:53<00:00, 10.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss 0.36304208636283875 || accuracy 0.876 || f1_score 0.8647847023518739\n"
          ]
        }
      ],
      "source": [
        "# model = phoBertGCN('/content/best_phoBert_GCN_model.pkl', dataset.label_num)\n",
        "\n",
        "with torch.no_grad():\n",
        "    eval(0, data_loader, model, features, graph, 'test', device, best_loss, best_accuracy, no_increasing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUFbxjukLxkf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-Qm_DII13AYh",
        "yQtcxg8Tz4-u",
        "AOpewssfyyRi",
        "Rjon6T-OtmPb",
        "47A_nGouvJVi",
        "DuY6Va1TmOTd",
        "cAmJ-_ndwFag",
        "rlbcFsY4y7Vb",
        "IepFinMmzJXb",
        "EJam6vuZz3rr"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0471d9c9aef848409945e852fe89b80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d58382d49784b37bf72b027087eb237": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e04d1208494c6c9ca811ab2d197440": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13995d512ea94a8fa09c07fbf6e8e187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16586df8986d477b906af5609395d161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18899397f90e47ceb538849974eb91bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7ec4380c6934d80a371d4666d40c6ee",
              "IPY_MODEL_27308b02666940949a37dbf4b649ed7b",
              "IPY_MODEL_6bdc77a21c24463b9e9d4d00a7da4a09"
            ],
            "layout": "IPY_MODEL_16586df8986d477b906af5609395d161"
          }
        },
        "1f2b535b68d5427289ffb3f7b0607c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa6649dade74cc7b4a3fba5b5186cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_13995d512ea94a8fa09c07fbf6e8e187",
            "value": " 557/557 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "27308b02666940949a37dbf4b649ed7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd3ea33d11c347b18ac432dab92940c3",
            "max": 895321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a98186f1f66d4ba8949d7f27f13ebea1",
            "value": 895321
          }
        },
        "295b279b4a5c4231af60655391a311f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2963fe54d0a844149bc3c2e129809170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdfc0c1f537c4a60ab0f650ab6ff30f4",
            "max": 557,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed97233c6fff4025964dafb2f118504d",
            "value": 557
          }
        },
        "2aa6649dade74cc7b4a3fba5b5186cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebc3d40fbef490c80f35eb4bd172df0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebdced46c384751a880207e634a1f82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bf7b3c72a54ba2a609eaec4b7a128a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34a54de438f642c68c970793a8be86de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b412395b3740ba88ea59691a8d5984",
              "IPY_MODEL_bc17ba5aa25d48fb997a39c712386407",
              "IPY_MODEL_c3687968bfed4f438edc7efa57e44c58"
            ],
            "layout": "IPY_MODEL_835f0e1f336a4b1bb14f3ea33ba088b8"
          }
        },
        "375523413d4e4a22aadbb5fa128f4ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "468fb9f6718448aca2c34023d5d79fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebdced46c384751a880207e634a1f82",
            "max": 1135173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33bf7b3c72a54ba2a609eaec4b7a128a",
            "value": 1135173
          }
        },
        "4b2356c1aa1e441ea37ed2c99a6d2285": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593fcc4c53ae4384a135115f5526cade": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b51af379c046d28c0a8b28cc94fbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "697a6841f3374692ae3344908cc654da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bdc77a21c24463b9e9d4d00a7da4a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7367e22612fd415494d3da2264753bab",
            "placeholder": "​",
            "style": "IPY_MODEL_68b51af379c046d28c0a8b28cc94fbf2",
            "value": " 895k/895k [00:00&lt;00:00, 2.56MB/s]"
          }
        },
        "71b84c6228f2429590dfbd7b79f54ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7367e22612fd415494d3da2264753bab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835f0e1f336a4b1bb14f3ea33ba088b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b340fa45b6f486e8962c4a8975bdb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d20b913337264667b3625f6126053c92",
              "IPY_MODEL_468fb9f6718448aca2c34023d5d79fe2",
              "IPY_MODEL_c1c9e6b8cd9b43eb8a577382d4fed4cd"
            ],
            "layout": "IPY_MODEL_d09c5901bf3d433faae0006a9017c5fd"
          }
        },
        "9bd8cf9690094c0f9eda7754346cdc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e04d1208494c6c9ca811ab2d197440",
            "placeholder": "​",
            "style": "IPY_MODEL_cd7f74228eb640b9baa506c5b01d2859",
            "value": "Downloading: 100%"
          }
        },
        "a98186f1f66d4ba8949d7f27f13ebea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc17ba5aa25d48fb997a39c712386407": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2356c1aa1e441ea37ed2c99a6d2285",
            "max": 542923308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_375523413d4e4a22aadbb5fa128f4ebf",
            "value": 542923308
          }
        },
        "bdfc0c1f537c4a60ab0f650ab6ff30f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c9e6b8cd9b43eb8a577382d4fed4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd65612714448e4928e72e08fff5637",
            "placeholder": "​",
            "style": "IPY_MODEL_e2f9630829584f209a2317b11fb44e49",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 2.80MB/s]"
          }
        },
        "c3687968bfed4f438edc7efa57e44c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c866dc4d6f414db2989b3a70ed2e4cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_697a6841f3374692ae3344908cc654da",
            "value": " 543M/543M [00:10&lt;00:00, 45.4MB/s]"
          }
        },
        "c7ec4380c6934d80a371d4666d40c6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593fcc4c53ae4384a135115f5526cade",
            "placeholder": "​",
            "style": "IPY_MODEL_71b84c6228f2429590dfbd7b79f54ff1",
            "value": "Downloading: 100%"
          }
        },
        "c866dc4d6f414db2989b3a70ed2e4cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3ea33d11c347b18ac432dab92940c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7f74228eb640b9baa506c5b01d2859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d09c5901bf3d433faae0006a9017c5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20b913337264667b3625f6126053c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebc3d40fbef490c80f35eb4bd172df0",
            "placeholder": "​",
            "style": "IPY_MODEL_295b279b4a5c4231af60655391a311f2",
            "value": "Downloading: 100%"
          }
        },
        "ddb198b6ff7a4081bc0bc56f0aae35ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bd8cf9690094c0f9eda7754346cdc14",
              "IPY_MODEL_2963fe54d0a844149bc3c2e129809170",
              "IPY_MODEL_1f2b535b68d5427289ffb3f7b0607c1e"
            ],
            "layout": "IPY_MODEL_0d58382d49784b37bf72b027087eb237"
          }
        },
        "dfd65612714448e4928e72e08fff5637": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f9630829584f209a2317b11fb44e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed97233c6fff4025964dafb2f118504d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6b412395b3740ba88ea59691a8d5984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8fddcb11f7543e48f9fd099f4a73dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_0471d9c9aef848409945e852fe89b80d",
            "value": "Downloading: 100%"
          }
        },
        "f8fddcb11f7543e48f9fd099f4a73dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
